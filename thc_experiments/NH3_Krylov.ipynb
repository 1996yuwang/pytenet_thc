{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "from pytenet.hartree_fock_mps import generate_single_state\n",
    "from pytenet.operation import add_mps, operator_average\n",
    "from pytenet.hamiltonian_thc import eval_func, generate_thc_mpos_by_layer_qn, get_t, get_h1_spin, get_g_spin\n",
    "from pytenet.global_krylov_method import generate_krylov_space_in_disk, get_W, get_S, generate_re_ortho_space_with_coeff, coeff_canonical_orthogonalization,  generate_linear_combination_mps\n",
    "from pytenet.global_krylov_method import solve_ritz, generate_reduced_H_non_ortho, remain_only_tridiagonal_elements, coeff_gram_schmidt, generate_Hamiltonian_with_occupation_number, solve_ritz_two_vec\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import copy\n",
    "import h5py\n",
    "from numpy.linalg import norm\n",
    "#np.set_printoptions(precision=4,suppress=True)\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pytenet as ptn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and initialize datas: \n",
    "\n",
    "no is number of spatial orbitals\n",
    "\n",
    "L is number of spinor orbitals, L = 2*no\n",
    "\n",
    "t_spin is one-body integral in Chemist's notation (considering spins)\n",
    "\n",
    "g_spin is two-body integral in Chemist's notation (considering spins)\n",
    "\n",
    "X_mo and Z_mo are THC tensors, X_mo_up/down are X_mo considering spins\n",
    "\n",
    "r_THC is THC rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "(8, 36)\n",
      "(36, 36)\n",
      "rl errV: 6.421105521729929e-13\n",
      "abs errV: 4.286591936668418e-12\n",
      "errt: 1.0574710399920436e-13\n",
      "errh: 1.8088404989173088e-14\n",
      "errht: 9.006422291220954e-14\n"
     ]
    }
   ],
   "source": [
    "#load integrals\n",
    "with h5py.File(\"/work_fast/ge49cag/code_datas/NH3/integral.hdf5\", \"r\") as f:\n",
    "#with h5py.File(\"/work_fast/ge49cag/pytenet_yu/water/eri_water.hdf5\", \"r\") as f:\n",
    "    eri = f[\"eri\"][()]\n",
    "    hkin = f[\"hkin\"][()]\n",
    "    hnuc = f[\"hnuc\"][()]\n",
    "\n",
    "#print(np.linalg.norm(eri))\n",
    "#print(eri.shape)\n",
    "\n",
    "no = eri.shape[0]\n",
    "MV = eri.reshape(no*no,no*no)\n",
    "\n",
    "u = np.load(\"/work_fast/ge49cag/code_datas/NH3/x.npy\")\n",
    "#u = np.load(\"/work_fast/ge49cag/pytenet_yu/water/x.npy\")\n",
    "X_mo = u.transpose(1,0)\n",
    "g_thc, Z_mo = eval_func(u,eri,hkin,hnuc,)\n",
    "h1 = hnuc+hkin\n",
    "nmo = X_mo.shape[1]\n",
    "L = 2*X_mo.shape[1]\n",
    "g_thc = g_thc.reshape(nmo, nmo, nmo, nmo)\n",
    "r_thc = X_mo.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H_correct = get_molecular_Hamiltonian_as_sparse_matrix(get_h1_spin(h1), get_g_spin(eri))\n",
    "H_correct = scipy.io.mmread('/work_fast/ge49cag/code_datas/H_correct_NH3.mtx').tocsr()\n",
    "# H_correct_10e = generate_Hamiltonian_with_occupation_number(H_correct.real, 10)\n",
    "# sparse.linalg.eigsh(H_correct_10e, which='SA', k = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ge49cag/.local/lib/python3.10/site-packages/scipy/sparse/_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "H_correct_10e = generate_Hamiltonian_with_occupation_number(H_correct.real, 10)\n",
    "e ,v = sparse.linalg.eigsh(H_correct_10e, which='SA', k = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_ground = e[0]\n",
    "e_1st_ex = e[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate elements in reduced Hamiltonian using conventional MPO.\n",
    "\n",
    "Since we only need to store ONE block during contraction, memory needed is only $\\mathcal{O}(L^2 M^2)$.\n",
    "\n",
    "Create conventional mpo for molecular Hamiltonian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 16, 62, 100, 154, 100, 62, 16, 1]\n"
     ]
    }
   ],
   "source": [
    "# h1_spin = get_h1_spin(h1)\n",
    "# g_spin = get_g_spin(eri)\n",
    "g_phy =  eri.transpose(0, 2, 1, 3)\n",
    "#mpo_ref = ptn.hamiltonian.molecular_hamiltonian_mpo(h1_spin, g_spin_phy)\n",
    "mpo_ref = ptn.hamiltonian.spin_molecular_hamiltonian_mpo(h1, g_phy)\n",
    "print(mpo_ref.bond_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate THC-MPO by layers, using THC tensors. \n",
    "t_spin is used to create MPO for kinetic term.\n",
    "It returns a list of H_mu_nu, each H_mu_nu is also a list, which contains four smaller MPOs with bond dims 2.\n",
    "The final element of this list is MPO for kinetic term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'pytenet.mpo.MPO'>\n",
      "[1, 2, 2, 2, 2, 2, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "#generate thc_mpo\n",
    "t = get_t(h1, eri)\n",
    "H_mu_nu_list_spin_layer = generate_thc_mpos_by_layer_qn(X_mo, Z_mo, L, t)\n",
    "\n",
    "print(type(H_mu_nu_list_spin_layer))\n",
    "print(type(H_mu_nu_list_spin_layer[0]))\n",
    "print(type(H_mu_nu_list_spin_layer[0][0]))\n",
    "print((H_mu_nu_list_spin_layer[0][0].bond_dims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ground state finding, we use Hatree fock state |11111111110000> as initial state.\n",
    "\n",
    "For 1st excited state, please use single-excited Hatree-Fock state as initial state, or even superposition of several single-excited Hatree-Fock states as initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp1 = generate_single_state(16, [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0])\n",
    "#initial = generate_single_state(16, [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0])\n",
    "\n",
    "HFS1 = generate_single_state(8, [3, 3, 3, 3, 3, 0, 0, 0])\n",
    "initial = copy.deepcopy(HFS1)\n",
    "#HFS2 = generate_single_state(8, [3, 3, 3, 3, 1, 2, 0, 0])\n",
    "#initial = copy.deepcopy(HFS2)\n",
    "#initial = add_mps(HFS1, HFS2)\n",
    "#initial.orthonormalize('left')\n",
    "#initial.orthonormalize('right')\n",
    "#hartree_state = add_mps(add_mps(add_mps(temp1, temp2), temp3),temp4)\n",
    "# hartree_state = add_mps(temp1, temp2)\n",
    "# hartree_state.orthonormalize('left')\n",
    "# hartree_state.orthonormalize('right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate Krylov space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 11, 19, 24, 22, 11, 4, 1]\n",
      "2\n",
      "[1, 4, 16, 48, 75, 54, 16, 4, 1]\n",
      "3\n",
      "[1, 4, 16, 59, 120, 62, 16, 4, 1]\n",
      "4\n",
      "[1, 4, 16, 63, 120, 63, 16, 4, 1]\n",
      "5\n",
      "[1, 4, 16, 63, 120, 64, 16, 4, 1]\n",
      "6\n",
      "[1, 4, 16, 63, 120, 64, 16, 4, 1]\n",
      "7\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "8\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "9\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "10\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "11\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "12\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "13\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "14\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "15\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "16\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "17\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "18\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "19\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "20\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "21\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "22\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "23\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "24\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "25\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "26\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "27\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "28\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "29\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "30\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "31\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "32\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "33\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "34\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "35\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "36\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "37\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "38\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "39\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "N_Krylov_1 = 40\n",
    "psi_original_1 = copy.deepcopy(initial)\n",
    "#psi_original_1 = copy.deepcopy(initial)\n",
    "max_bond_Krylov_1 = 120\n",
    "trunc_tol = 1e-12\n",
    "foldername_1 = f\"/work_fast/ge49cag/code_datas/NH3_ground\"\n",
    "generate_krylov_space_in_disk(N_Krylov_1, H_mu_nu_list_spin_layer, psi_original_1, max_bond_Krylov_1, trunc_tol, r_thc, foldername_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work_fast/ge49cag/pytenet_thc_spin_cons/thc_experiments/../pytenet/global_krylov_method.py:214: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  H_reduced[i, j] = operator_inner_product(temp1, H_mpo, temp2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work_fast/ge49cag/pytenet_thc_spin_cons/thc_experiments/../pytenet/global_krylov_method.py:113: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  W[i,j] = vdot(temp1, temp2)\n"
     ]
    }
   ],
   "source": [
    "H_reduced_non_rotho_1 = generate_reduced_H_non_ortho(N_Krylov_1, foldername_1, mpo_ref)\n",
    "coeff_1 = coeff_gram_schmidt(N_Krylov_1, foldername_1)\n",
    "#H_reduced: elements calculated by post-orthogonalized Krylov vectos\n",
    "H_reduced_1 = np.einsum('ik, kl, jl -> ij', coeff_1.conj(), H_reduced_non_rotho_1, coeff_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8114606484471096+0j)\n",
      "(0.05698845992996837+0j)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.002942826023840439+0j)\n",
      "(0.00034125054853006986+0j)\n",
      "(3.187003225946228e-05+0j)\n",
      "(3.1331363175013394e-06+0j)\n",
      "(2.8760003658589994e-06+0j)\n",
      "(2.8548589199317576e-06+0j)\n"
     ]
    }
   ],
   "source": [
    "e_ritz_1, v_ritz_1 = solve_ritz(foldername_1, H_reduced_1, N_Krylov_1, coeff_1, max_bond_Krylov_1, e_ground, mpo_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e_krylov_1, v_krylov_1 = np.linalg.eigh(H_reduced_1)\n",
    "# shift = e_krylov_1[0]\n",
    "# Q_1, R_1 = np.linalg.qr(H_reduced_1 - shift*np.identity(H_reduced_1.shape[0]))\n",
    "\n",
    "# coeff_shifted_1 = np.einsum('ai, ab -> ib', Q_1, coeff_1)\n",
    "# #H_shifted_1 = np.einsum('ik, kl, jl -> ij', coeff_shifted_1.conj(), H_reduced_non_rotho_1, coeff_shifted_1)\n",
    "# #H_shifted_1 = coeff_shifted_1 @H_reduced_non_rotho_1 @coeff_shifted_1.T "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "2\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "3\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "4\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "5\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "6\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "7\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "8\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "9\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "10\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "11\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "12\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "13\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "14\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "15\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "16\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "17\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "18\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "19\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "20\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "21\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "22\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "23\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "24\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "25\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "26\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "27\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "28\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "29\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "N_Krylov_2 = 30\n",
    "psi_original_2 = copy.deepcopy(v_ritz_1)\n",
    "max_bond_Krylov_2 = 120\n",
    "trunc_tol = 0\n",
    "foldername_2= f\"/work_fast/ge49cag/code_datas/NH3_ground_restart1\"\n",
    "generate_krylov_space_in_disk(N_Krylov_2, H_mu_nu_list_spin_layer, psi_original_2, max_bond_Krylov_2, trunc_tol, r_thc, foldername_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_reduced_non_rotho_2 = generate_reduced_H_non_ortho(N_Krylov_2, foldername_2, mpo_ref)\n",
    "coeff_2 = coeff_gram_schmidt(N_Krylov_2, foldername_2)\n",
    "#H_reduced: elements calculated by post-orthogonalized Krylov vectos\n",
    "H_reduced_2 = np.einsum('ik, kl, jl -> ij', coeff_2.conj(), H_reduced_non_rotho_2, coeff_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.833380506217509e-06+0j)\n",
      "(2.8310391968489057e-06+0j)\n",
      "(2.8278486183808127e-06+0j)\n",
      "(2.8213683691546976e-06+0j)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.8115766923519914e-06+0j)\n",
      "(2.8072056750261254e-06+0j)\n"
     ]
    }
   ],
   "source": [
    "e_ritz_2, v_ritz_2 = solve_ritz(foldername_2, H_reduced_2, N_Krylov_2, coeff_2, max_bond_Krylov_2, e_ground, mpo_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "2\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "3\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "4\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "5\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "6\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "7\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "8\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "9\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "10\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "11\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "12\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "13\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "14\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "N_Krylov_3 = 15\n",
    "psi_original_3 = copy.deepcopy(v_ritz_2)\n",
    "max_bond_Krylov_3 = 120\n",
    "trunc_tol = 0\n",
    "foldername_3 = f\"/work_fast/ge49cag/code_datas/NH3_ground_restart2\"\n",
    "generate_krylov_space_in_disk(N_Krylov_3, H_mu_nu_list_spin_layer, psi_original_3, max_bond_Krylov_3, trunc_tol, r_thc, foldername_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_reduced_non_rotho_3 = generate_reduced_H_non_ortho(N_Krylov_3, foldername_3, mpo_ref)\n",
    "coeff_3 = coeff_gram_schmidt(N_Krylov_3, foldername_3)\n",
    "#H_reduced: elements calculated by post-orthogonalized Krylov vectos\n",
    "H_reduced_3 = np.einsum('ik, kl, jl -> ij', coeff_3.conj(), H_reduced_non_rotho_3, coeff_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.8058482541837293e-06+0j)\n",
      "(2.805044601927875e-06+0j)\n",
      "(2.804613842499748e-06+0j)\n"
     ]
    }
   ],
   "source": [
    "e_ritz_3, v_ritz_3 = solve_ritz(foldername_3, H_reduced_3, N_Krylov_3, coeff_3, max_bond_Krylov_3, e_ground, mpo_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "2\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "3\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "4\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "5\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "6\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "7\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "8\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "9\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "10\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "11\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "12\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "13\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n",
      "14\n",
      "[1, 4, 16, 64, 120, 64, 16, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "N_Krylov_4 = 15\n",
    "psi_original_4 = copy.deepcopy(v_ritz_3)\n",
    "max_bond_Krylov_4 = 120\n",
    "trunc_tol = 0\n",
    "foldername_4 = f\"/work_fast/ge49cag/code_datas/NH3_ground_restart3\"\n",
    "generate_krylov_space_in_disk(N_Krylov_4, H_mu_nu_list_spin_layer, psi_original_4, max_bond_Krylov_4, trunc_tol, r_thc, foldername_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_reduced_non_rotho_4 = generate_reduced_H_non_ortho(N_Krylov_4, foldername_4, mpo_ref)\n",
    "coeff_4 = coeff_gram_schmidt(N_Krylov_4, foldername_4)\n",
    "#H_reduced: elements calculated by post-orthogonalized Krylov vectos\n",
    "H_reduced_4 = np.einsum('ik, kl, jl -> ij', coeff_4.conj(), H_reduced_non_rotho_4, coeff_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.802988561256825e-06+0j)\n",
      "(2.802121031209026e-06+0j)\n",
      "(2.8017927462542502e-06+0j)\n"
     ]
    }
   ],
   "source": [
    "e_ritz_4, v_ritz_4 = solve_ritz(foldername_4, H_reduced_4, N_Krylov_4, coeff_4, max_bond_Krylov_4, e_ground, mpo_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To say it is not THC's issue, we could also use H_ref to calculate lanczos as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = f\"/work_fast/ge49cag/code_datas\" + f\"/NH3_ground_state.pkl\"\n",
    "# with open(filename, 'wb') as file:\n",
    "#     pickle.dump(v_ritz_4, file)\n",
    "\n",
    "# filename = f\"/work_fast/ge49cag/code_datas\" + f\"/NH3_ground_state.pkl\"\n",
    "# with open(filename, 'rb') as file:\n",
    "#     NH3_ground = pickle.load(file)\n",
    "\n",
    "# operator_average(NH3_ground, mpo_ref) - e_ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2187624976048994+0j)\n"
     ]
    }
   ],
   "source": [
    "e_4, v_4 = np.linalg.eigh(H_reduced_4)\n",
    "NH3_1st_excited =  generate_linear_combination_mps(N_Krylov_4, v_4[:,1], max_bond_Krylov_4, foldername_4)\n",
    "print(operator_average(NH3_1st_excited, mpo_ref) - e_1st_ex)\n",
    "\n",
    "# filename = f\"/work_fast/ge49cag/code_datas\" + f\"/NH3_1st_excited.pkl\"\n",
    "# with open(filename, 'wb') as file:\n",
    "#     pickle.dump(NH3_1st_excited, file)\n",
    "    \n",
    "# filename = f\"/work_fast/ge49cag/code_datas\" + f\"/NH3_1st_excited.pkl\"\n",
    "# with open(filename, 'rb') as file:\n",
    "#     NH3_1st_excited = pickle.load(file)\n",
    "\n",
    "# print(operator_average(NH3_1st_excited, mpo_ref) - e_1st_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_remove = copy.deepcopy(NH3_ground)\n",
    "# to_remove.A[0] = -ptn.operation.vdot(to_remove, copy.deepcopy(NH3_1st_excited))* to_remove.A[0]\n",
    "# #compress the bond dims back \n",
    "# NH3_1st_excited =  ptn.operation_thc.add_mps_and_compress(copy.deepcopy(NH3_1st_excited), to_remove, 0, 200)\n",
    "# NH3_1st_excited.orthonormalize('right')\n",
    "# print(operator_average(NH3_1st_excited, mpo_ref) - e_1st_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = f\"/work_fast/ge49cag/code_datas\" + f\"/NH3_1st_excited.pkl\"\n",
    "# with open(filename, 'wb') as file:\n",
    "#     pickle.dump(NH3_1st_excited, file)\n",
    "\n",
    "# filename = f\"/work_fast/ge49cag/code_datas\" + f\"/NH3_1st_excited.pkl\"\n",
    "# with open(filename, 'rb') as file:\n",
    "#     NH3_1st_excited = pickle.load(file)\n",
    "\n",
    "# print(operator_average(NH3_1st_excited, mpo_ref) - e_1st_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -ptn.operation.vdot(NH3_1st_excited, NH3_ground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
