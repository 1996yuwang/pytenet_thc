{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "from pytenet.hartree_fock_mps import generate_single_state\n",
    "from pytenet.hamiltonian_thc import eval_func, generate_thc_mpos_by_layer_qn, get_t, get_h1_spin, get_g_spin\n",
    "from pytenet.global_krylov_method import generate_krylov_space_in_disk, get_W, get_S, remain_only_tridiagonal_elements\n",
    "from pytenet.global_krylov_method import generate_Hamiltonian_with_occupation_number, generate_reduced_H_non_ortho, store_file\n",
    "from pytenet.operation_thc import apply_thc_mpo_and_compress, add_mps_and_compress\n",
    "from pytenet.operation import vdot, add_mps\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import copy\n",
    "import h5py\n",
    "from numpy.linalg import norm\n",
    "#np.set_printoptions(precision=4,suppress=True)\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pytenet as ptn\n",
    "import scipy.sparse.linalg as spla\n",
    "from pytenet.krylov_time_evo import ED_time_evo, Krylov_evo_using_vecs_single_step, Krylov_time_evo_using_vecs, Krylov_evo_using_built_space, create_Krylov_space, gram_schmidt, Krylov_evo_using_built_mps_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load integrals\n",
    "with h5py.File(\"../data_water/eri_water.hdf5\", \"r\") as f:\n",
    "#with h5py.File(\"/work_fast/ge49cag/pytenet_yu/water/eri_water.hdf5\", \"r\") as f:\n",
    "    eri = f[\"eri\"][()]\n",
    "    hkin = f[\"hkin\"][()]\n",
    "    hnuc = f[\"hnuc\"][()]\n",
    "\n",
    "#print(np.linalg.norm(eri))\n",
    "#print(eri.shape)\n",
    "\n",
    "no = eri.shape[0]\n",
    "MV = eri.reshape(no*no,no*no)\n",
    "\n",
    "u = np.load(\"../data_water/x.npy\")\n",
    "#u = np.load(\"/work_fast/ge49cag/pytenet_yu/water/x.npy\")\n",
    "X_mo = u.transpose(1,0)\n",
    "g_thc, Z_mo = eval_func(u,eri,hkin,hnuc,)\n",
    "h1 = hnuc+hkin\n",
    "nmo = X_mo.shape[1]\n",
    "L = X_mo.shape[1]\n",
    "g_thc = g_thc.reshape(nmo, nmo, nmo, nmo)\n",
    "r_thc = X_mo.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h1_spin = get_h1_spin(h1)\n",
    "# g_spin = get_g_spin(eri)\n",
    "g_phy =  eri.transpose(0, 2, 1, 3)\n",
    "#mpo_ref = ptn.hamiltonian.molecular_hamiltonian_mpo(h1_spin, g_spin_phy)\n",
    "mpo_ref = ptn.hamiltonian.spin_molecular_hamiltonian_mpo(h1, g_phy)\n",
    "print(mpo_ref.bond_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref Hamiltonian as matrix\n",
    "H_ref = scipy.io.mmread('../data_water/H_water_correct.mtx').tocsr()\n",
    "H_thc = scipy.io.mmread('../data_water/H_water_thc.mtx').tocsr()\n",
    "\n",
    "#initial state\n",
    "filename = f\"/work_fast/ge49cag/code_datas\" + f\"/water_ground_ionization.pkl\"\n",
    "with open(filename, 'rb') as file:\n",
    "    initial_state = pickle.load(file)\n",
    "\n",
    "#thc mpo\n",
    "t = get_t(h1, eri)\n",
    "H_mu_nu_list_spin_layer = generate_thc_mpos_by_layer_qn(X_mo, Z_mo, L, t)\n",
    "r_THC = int((len(H_mu_nu_list_spin_layer)-1)**(1/2) / 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#N_krylov = 4\n",
    "\n",
    "# psi_krylov_ref = Krylov_time_evo_using_vecs(H_ref, N_krylov, initial_state.as_vector(), 1, 0.03)\n",
    "# psi_ed = ED_time_evo(H_ref, initial_state.as_vector(), 0.03)\n",
    "# print('total swift:', norm(psi_ed - initial_state.as_vector()))\n",
    "# print(norm(psi_krylov_ref - psi_ed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for i in range(n):\n",
    "first update foldername\n",
    "generate_krylov_space_in_disk(N_Krylov, H_mu_nu_list_spin_layer, psi_original, max_bond_Krylov, trunc_tol, r_THC, foldername)\n",
    "then calculate time-evolved state (with re-ortho)\n",
    "'''\n",
    "#不需要创造很多文件夹储存文件，对每个文件好好命名然后都存在同一个文件夹即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use max_bond, don't set truncation tol!\n",
    "# need introduce min_bond again to reduce error, when using trunc as parameters\n",
    "\n",
    "\n",
    "\"\"\"dt_list = [0.005, 0.008, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.15, 0.2, 0.3, 0.5]\n",
    "max_bond_list = [25, 30, 35, 40]\n",
    "\n",
    "\n",
    "for max_bond in max_bond_list:\n",
    "    print (max_bond)\n",
    "    space_test = create_Krylov_space(N_krylov, H_mu_nu_list_spin_layer, copy.deepcopy(initial_state), 0, max_bond, r_THC)\n",
    "    for dt in dt_list:\n",
    "        print (dt)\n",
    "        psi_krylov_ref = Krylov_time_evo_using_vecs(H_ref, N_krylov, initial_state.as_vector(), 1, dt)\n",
    "        psi_ed = ED_time_evo(H_ref, initial_state.as_vector(), dt)\n",
    "        vec_mps_test = Krylov_evo_using_built_mps_space(mpo_ref, space_test, max_bond, dt)\n",
    "        print('trunc error', norm(vec_mps_test.as_vector() - psi_krylov_ref))\n",
    "        print('krylov error', norm(psi_krylov_ref - psi_ed))\n",
    "        print('total error', norm(vec_mps_test.as_vector() - psi_ed))\"\"\"\n",
    "        \n",
    "        \n",
    "        \n",
    "# 用总时间1au画误差分析\n",
    "# 用总时间1fs = 40au画D=30/40时候的误差图（或许可以说明误差累积/以及由于纠缠，误差增长变快）\n",
    "# 并且比较内存使用\n",
    "# 或许也可以画\n",
    "\n",
    "# data: dt, bond_dim as a group\n",
    "# always generate data which does not the same parameters.\n",
    "# as a test, we can do it for dt = 0.05 and 0.1, for bond_dim = 30 and 35, total time 1\n",
    "# maybe start from T = 1 and dt = 0.1 and bond_dim = 35\n",
    "# error: only compare the final error instead of each steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def store_file(foldername, filename, temp):\n",
    "#     filename = foldername + filename\n",
    "#     with open(filename, 'wb') as file:\n",
    "#         pickle.dump(temp, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 0.3\n",
    "dt = 0.1\n",
    "n = round(T / dt)\n",
    "N_krylov = 4\n",
    "max_bond = 35\n",
    "foldername = f\"/work_fast/ge49cag/code_datas/water_time_evo\"\n",
    "\n",
    "for i in range(n):\n",
    "    if i == 0:\n",
    "        space_test = create_Krylov_space(N_krylov, H_mu_nu_list_spin_layer, copy.deepcopy(initial_state), 0, max_bond, r_THC)\n",
    "        time_evolved_mps = Krylov_evo_using_built_mps_space(mpo_ref, space_test, max_bond, dt)\n",
    "        store_file(foldername, f\"/Krylov_space{N_krylov}{max_bond}{dt}{i}.pkl\", time_evolved_mps)\n",
    "        \n",
    "    else:\n",
    "        space_test = create_Krylov_space(N_krylov, H_mu_nu_list_spin_layer, copy.deepcopy(time_evolved_mps), 0, max_bond, r_THC)\n",
    "        time_evolved_mps = Krylov_evo_using_built_mps_space(mpo_ref, space_test, max_bond, dt)\n",
    "        store_file(foldername, f\"/Krylov_space{N_krylov}{max_bond}{dt}{i}.pkl\", time_evolved_mps)\n",
    "\n",
    "psi_ed = ED_time_evo(H_ref, initial_state.as_vector(), T)\n",
    "psi_krylov_ref = Krylov_time_evo_using_vecs(H_ref, N_krylov, initial_state.as_vector(), n, T)\n",
    "\n",
    "print('trunc error', norm(time_evolved_mps.as_vector() - psi_krylov_ref))\n",
    "print('krylov error', norm(psi_krylov_ref - psi_ed))\n",
    "print('total error', norm(time_evolved_mps.as_vector() - psi_ed))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt = 0.03\n",
    "\n",
    "# Krylov_mps_list = copy.deepcopy(space_test)\n",
    "# TN = np.zeros([len(Krylov_mps_list),len(Krylov_mps_list)])\n",
    "# for i in range (TN.shape[0]):\n",
    "#     for j in range (TN.shape[1]):\n",
    "#         if abs(i - j) < 2:\n",
    "#             TN[i, j] = ptn.operation.operator_inner_product(Krylov_mps_list[i], mpo_ref, Krylov_mps_list[j])\n",
    "            \n",
    "# c1 = np.zeros([len(Krylov_mps_list), 1])\n",
    "# c1[0,0] = 1\n",
    "# exp_TN = spla.expm(-1j*dt*TN)\n",
    "# c_reduced = exp_TN@ c1\n",
    "\n",
    "# psi_evloved = copy.deepcopy(Krylov_mps_list[0])\n",
    "# psi_evloved.A[0] = c_reduced[0] *psi_evloved.A[0]\n",
    "\n",
    "# for i in range (1, len(Krylov_mps_list), 1):\n",
    "#     temp = copy.deepcopy(Krylov_mps_list[i])\n",
    "#     temp.A[0] = c_reduced[i] *temp.A[0]\n",
    "#     psi_evloved = add_mps(psi_evloved, temp)\n",
    "    \n",
    "# print(norm(psi_evloved.as_vector() - psi_krylov_ref))\n",
    "# psi_evloved.orthonormalize('right')\n",
    "# psi_evloved.orthonormalize('left')\n",
    "\n",
    "\n",
    "# psi_evloved.compress_direct_svd_right_max_bond(0, max_bond)\n",
    "# psi_evloved.orthonormalize('right')\n",
    "# psi_evloved.orthonormalize('left')\n",
    "    \n",
    "# print(norm(psi_evloved.as_vector() - psi_krylov_ref))\n",
    "# print(norm(psi_evloved.as_vector() - psi_ed))\n",
    "# print(norm(psi_krylov_ref - psi_ed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /tmp/ipykernel_3032840/2463284093.py:8: ComplexWarning: Casting complex values to real discards the imaginary part\n",
    "#   TN[i, j] = ptn.operation.operator_inner_product(Krylov_mps_list[i], mpo_ref, Krylov_mps_list[j])\n",
    "# 3.5432687797238603e-06\n",
    "# 9.462310845684574e-06\n",
    "# 1.093342968130352e-05\n",
    "# 5.4866900147348975e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space_test_vec = []\n",
    "# for i in range (len(space_test)):\n",
    "#     temp = space_test[i].as_vector()\n",
    "#     temp /= norm(temp)\n",
    "#     space_test_vec.append(temp)\n",
    "\n",
    "# space_test_vec = gram_schmidt(space_test_vec)\n",
    "\n",
    "# space_test_vec = [mps_krylov.as_vector() for mps_krylov in space_test]\n",
    "# space_test_vec = gram_schmidt(space_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #only use max_bond, don't set truncation tol!\n",
    "# vec_test = Krylov_evo_using_built_space(H_ref, space_test_vec, 0.05)\n",
    "# print(norm(vec_test - psi_krylov_ref))\n",
    "# print(norm(vec_test - psi_ed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt = 0.03\n",
    "\n",
    "# D = 45:\n",
    "\n",
    "\n",
    "\n",
    "# D = 40:\n",
    "# 7.159356839258043e-13 (trunc error)\n",
    "# 5.486690011281797e-06 (total error)\n",
    "\n",
    "# D = 35\n",
    "# 3.537471270532817e-06 (trunc error)\n",
    "# 6.522437168647089e-06 (total error)\n",
    "\n",
    "# D= 30\n",
    "# 0.0004761841209985205 (trunc error)\n",
    "# 0.00047618669594564364 (total error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
