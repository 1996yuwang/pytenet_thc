{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In water_Krylov_example, the scalers are calculated using the np.array form from MPS.\n",
    "\n",
    "However, one should do it only using MPS form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pytenet.hartree_fock_mps import generate_single_state\n",
    "from pytenet.hamiltonian_thc import eval_func, generate_thc_mpos_by_layer_qn, get_t_spin, get_h1_spin, get_g_spin\n",
    "from pytenet.global_krylov_method import generate_krylov_space_in_disk, get_W, get_S, generate_re_ortho_space_with_coeff, coeff_canonical_orthogonalization, remain_only_tridiagonal_elements\n",
    "from pytenet.global_krylov_method import generate_re_ortho_space, generate_reduced_H, generate_Hamiltonian_with_occupation_number, generate_reduced_H_non_ortho\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import copy\n",
    "import h5py\n",
    "from numpy.linalg import norm\n",
    "#np.set_printoptions(precision=4,suppress=True)\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pytenet as ptn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and initialize datas: \n",
    "\n",
    "no is number of spatial orbitals\n",
    "\n",
    "L is number of spinor orbitals, L = 2*no\n",
    "\n",
    "t_spin is one-body integral in Chemist's notation (considering spins)\n",
    "\n",
    "g_spin is two-body integral in Chemist's notation (considering spins)\n",
    "\n",
    "X_mo and Z_mo are THC tensors, X_mo_up/down are X_mo considering spins\n",
    "\n",
    "r_THC is THC rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "(7, 28)\n",
      "(28, 28)\n",
      "rl errV: 2.8386751875274264e-12\n",
      "abs errV: 2.0615721155266396e-11\n",
      "errt: 7.097049412242525e-13\n",
      "errh: 2.585427402664151e-13\n",
      "errht: 9.079449636842276e-14\n"
     ]
    }
   ],
   "source": [
    "#load integrals\n",
    "with h5py.File(\"data_water/eri_water.hdf5\", \"r\") as f:\n",
    "#with h5py.File(\"/work_fast/ge49cag/pytenet_yu/water/eri_water.hdf5\", \"r\") as f:\n",
    "    eri = f[\"eri\"][()]\n",
    "    hkin = f[\"hkin\"][()]\n",
    "    hnuc = f[\"hnuc\"][()]\n",
    "\n",
    "#print(np.linalg.norm(eri))\n",
    "#print(eri.shape)\n",
    "\n",
    "no = eri.shape[0]\n",
    "MV = eri.reshape(no*no,no*no)\n",
    "\n",
    "u = np.load(\"data_water/x.npy\")\n",
    "#u = np.load(\"/work_fast/ge49cag/pytenet_yu/water/x.npy\")\n",
    "X_mo = u.transpose(1,0)\n",
    "g_thc, Z_mo = eval_func(u,eri,hkin,hnuc,)\n",
    "h1 = hnuc+hkin\n",
    "nmo = X_mo.shape[1]\n",
    "L = 2*X_mo.shape[1]\n",
    "g_thc = g_thc.reshape(nmo, nmo, nmo, nmo)\n",
    "r_thc = X_mo.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These Hamiltonian are exact molecular Hamiltonian and molecular Hamiltonian reconstructed by THC tensors. The calculation cost time, so that we store them in disk and load them when needed. For water molecule H2O in STO-6G basis, the error is small for r_THC = 28.\n",
    "\n",
    "Actually, considering there are always 10 electrons for a water molecule, we only retain the elements which operator quantum states with 10 electrons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ge49cag/.local/lib/python3.10/site-packages/scipy/sparse/_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "#load Hamiltonian generated by above coefficients\n",
    "H_correct = scipy.io.mmread('data_water/H_water_correct.mtx').tocsr()\n",
    "H_correct_10e = generate_Hamiltonian_with_occupation_number(H_correct.real, 10)\n",
    "e, v = sparse.linalg.eigsh(H_correct_10e, which = 'SA', k = 30)\n",
    "e_ground = e[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate elements in reduced Hamiltonian using conventional MPO.\n",
    "\n",
    "Since we only need to store ONE block during contraction, memory needed is only $\\mathcal{O}(L^2 M^2)$.\n",
    "\n",
    "Create conventional mpo for molecular Hamiltonian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 16, 39, 58, 75, 96, 115, 96, 75, 58, 39, 16, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "h1_spin = get_h1_spin(h1)\n",
    "g_spin = get_g_spin(eri)\n",
    "g_spin_phy =  g_spin.transpose(0, 2, 1, 3)\n",
    "mpo_ref = ptn.hamiltonian.molecular_hamiltonian_mpo(h1_spin, g_spin_phy)\n",
    "print(mpo_ref.bond_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate THC-MPO by layers, using THC tensors. \n",
    "t_spin is used to create MPO for kinetic term.\n",
    "It returns a list of H_mu_nu, each H_mu_nu is also a list, which contains four smaller MPOs with bond dims 2.\n",
    "The final element of this list is MPO for kinetic term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'pytenet.mpo.MPO'>\n",
      "[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "#generate thc_mpo\n",
    "t_spin = get_t_spin(h1, eri)\n",
    "H_mu_nu_list_spin_layer = generate_thc_mpos_by_layer_qn(X_mo, Z_mo, L, t_spin)\n",
    "\n",
    "print(type(H_mu_nu_list_spin_layer))\n",
    "print(type(H_mu_nu_list_spin_layer[0]))\n",
    "print(type(H_mu_nu_list_spin_layer[0][0]))\n",
    "print((H_mu_nu_list_spin_layer[0][0].bond_dims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use first several Hartree states to search for the low-lying states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hartree_state = generate_single_state(14, [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0])\n",
    "other_state1 = generate_single_state(14, [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0])\n",
    "other_state2 = generate_single_state(14, [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0])\n",
    "other_state3 = generate_single_state(14, [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0])\n",
    "other_state4 = generate_single_state(14, [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0])\n",
    "initial = ptn.operation.add_mps(hartree_state, other_state1)\n",
    "initial = ptn.operation.add_mps(initial, other_state2)\n",
    "initial = ptn.operation.add_mps(initial, other_state3)\n",
    "initial = ptn.operation.add_mps(initial, other_state4)\n",
    "initial.orthonormalize('left')\n",
    "initial.orthonormalize('right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate a group of orthogonal Krylov vectors using THC-MPO, with bond dim 40 for Krylov vectors. The vectors are stored in the folder = 'foldername', thus you don't have to generate them again for next time use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Krylov = 100\n",
    "psi_original = copy.deepcopy(initial)\n",
    "#max_bond_Krylov = 80\n",
    "max_bond_Krylov = 100\n",
    "trunc_tol = 0\n",
    "foldername = f\"water_Krylov_random\"\n",
    "#Krylov vectors are included in data, you dont have to run generate it. ofc, you can -regenerate it to verify the algorithm using the following code:\n",
    "\n",
    "#generate_krylov_space_in_disk(N_Krylov, H_mu_nu_list_spin_layer, psi_original, max_bond_Krylov, trunc_tol, r_thc, foldername)\n",
    "\n",
    "# it indicates that even though during the calculation the bond dims exceed 40, but we only need 37 for Krylov vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make use of method proposed in https://journals.aps.org/prb/abstract/10.1103/PhysRevB.85.205119 to improve the orthogonality of Krylov vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work_fast/ge49cag/pytenet_thc/pytenet/global_krylov_method.py:193: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  H_reduced[i, j] = operator_inner_product(temp1, H_mpo, temp2)\n",
      "/work_fast/ge49cag/pytenet_thc/pytenet/global_krylov_method.py:106: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  W[i,j] = np.vdot(temp1.as_vector(), temp2.as_vector())\n"
     ]
    }
   ],
   "source": [
    "N_use = 50\n",
    "# C = coeff_canonical_orthogonalization(N_use, foldername)\n",
    "# vector_list = generate_re_ortho_space_with_coeff(N_use, C, foldername)\n",
    "#vector_list = generate_re_ortho_space(N_use, foldername)\n",
    "H_reduced_non_rotho = generate_reduced_H_non_ortho(N_use, foldername, mpo_ref)\n",
    "W = get_W(N_use, foldername)\n",
    "coeff = get_S(W)\n",
    "coeff = np.array(coeff)\n",
    "H_reduced = np.einsum('ik, kl, jl -> ij', coeff.conj(), H_reduced_non_rotho, coeff)\n",
    "H_reduced = remain_only_tridiagonal_elements(H_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a mask for the tridiagonal elements\n",
    "# tridiag_mask = np.eye(H_reduced.shape[0], k=0, dtype=bool) | \\\n",
    "#                np.eye(H_reduced.shape[0], k=1, dtype=bool) | \\\n",
    "#                np.eye(H_reduced.shape[0], k=-1, dtype=bool)\n",
    "\n",
    "# # Apply the mask to retain only tridiagonal elements\n",
    "# H_reduced = np.where(tridiag_mask, H_reduced, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #check orthogonality:\n",
    "# for i in range (N_use):\n",
    "#     for j in range (N_use):\n",
    "#         if i!=j:\n",
    "#             #assert abs(np.vdot(vector_list[i], vector_list[j])) < 1e-8\n",
    "#             print(np.vdot(vector_list[i], vector_list[j])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After achieving Krylov vectors, we implement Lanczos algorithm using these Krylov vectors. In this notebook, all the expectation values are calculated using ED for convenience. Since calculating the expectation value (contracting the tensor network) doesn't bring new errors, it makes no difference whether we use tensor network or ED to calculate the matrix elements for reduced Hamiltonian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_list = [0]\n",
    "mps_start = copy.deepcopy(initial)\n",
    "error_list = [ptn.operation.operator_inner_product(mps_start, mpo_ref, mps_start) - e_ground]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5393176764736154\n",
      "0.29789909259795877\n",
      "0.04169765043963025\n",
      "0.004023182907445744\n",
      "0.00039939285501588984\n",
      "9.780577755691411e-06\n",
      "4.2517692122601147e-07\n",
      "2.445409563733847e-08\n",
      "8.737828238736256e-10\n",
      "5.329070518200751e-10\n"
     ]
    }
   ],
   "source": [
    "for N in range(5, N_use+1, 5):\n",
    "    N_list.append(N)\n",
    "    H_part = H_reduced[:N, :N]\n",
    "    e_rotate, v_rotate = np.linalg.eigh(H_part)\n",
    "\n",
    "    v_rotate_ground_coeff = v_rotate[:,0]\n",
    "    e_rotate_ground = np.vdot(v_rotate_ground_coeff, H_reduced_non_rotho[:N, :N]@v_rotate_ground_coeff)\n",
    "    #e_rotate_ground = np.einsum(', ,  -> ', v_rotate_ground_coeff.conj(), H_reduced_non_rotho, v_rotate_ground_coeff)\n",
    "    #e_new = np.vdot(v_rotate_ground, H_correct_10e@v_rotate_ground)\n",
    "    error_list.append(e_rotate_ground - e_ground)\n",
    "    \n",
    "    print(e_rotate_ground - e_ground)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#to do: using superposition state as initial to check the eigenvalues."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
