{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pytenet.hartree_fock_mps import generate_single_state\n",
    "from pytenet.operation import add_mps\n",
    "from pytenet.hamiltonian_thc import eval_func, generate_thc_mpos_by_layer_qn, get_t_spin, get_h1_spin, get_g_spin\n",
    "from pytenet.global_krylov_method import generate_krylov_space_in_disk, get_W, get_S, generate_re_ortho_space_with_coeff, coeff_canonical_orthogonalization, remain_only_tridiagonal_elements\n",
    "from pytenet.global_krylov_method import generate_re_ortho_space, generate_reduced_H, generate_Hamiltonian_with_occupation_number, generate_reduced_H_non_ortho, remain_only_tridiagonal_elements\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import copy\n",
    "import h5py\n",
    "from numpy.linalg import norm\n",
    "#np.set_printoptions(precision=4,suppress=True)\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pytenet as ptn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and initialize datas: \n",
    "\n",
    "no is number of spatial orbitals\n",
    "\n",
    "L is number of spinor orbitals, L = 2*no\n",
    "\n",
    "t_spin is one-body integral in Chemist's notation (considering spins)\n",
    "\n",
    "g_spin is two-body integral in Chemist's notation (considering spins)\n",
    "\n",
    "X_mo and Z_mo are THC tensors, X_mo_up/down are X_mo considering spins\n",
    "\n",
    "r_THC is THC rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "(10, 27)\n",
      "(27, 27)\n",
      "rl errV: 0.00023694902148543046\n",
      "abs errV: 0.0007546522262828301\n",
      "errt: 0.0008451096565123393\n",
      "errh: 0.00013317184525868722\n",
      "errht: 0.00024513110698447764\n"
     ]
    }
   ],
   "source": [
    "#load integrals\n",
    "#with h5py.File(\"data_water/eri_water.hdf5\", \"r\") as f:\n",
    "with h5py.File(\"/work_fast/ge49cag/code_datas/hchain/NH_10/integral.hdf5\", \"r\") as f:\n",
    "    eri = f[\"eri\"][()]\n",
    "    hkin = f[\"hkin\"][()]\n",
    "    hnuc = f[\"hnuc\"][()]\n",
    "\n",
    "#print(np.linalg.norm(eri))\n",
    "#print(eri.shape)\n",
    "\n",
    "no = eri.shape[0]\n",
    "MV = eri.reshape(no*no,no*no)\n",
    "\n",
    "u = np.load(\"/work_fast/ge49cag/code_datas/hchain/NH_10/u.npy\")\n",
    "#u = np.load(\"/work_fast/ge49cag/pytenet_yu/water/x.npy\")\n",
    "X_mo = u.transpose(1,0)\n",
    "g_thc, Z_mo = eval_func(u,eri,hkin,hnuc,)\n",
    "h1 = hnuc+hkin\n",
    "nmo = X_mo.shape[1]\n",
    "L = 2*X_mo.shape[1]\n",
    "g_thc = g_thc.reshape(nmo, nmo, nmo, nmo)\n",
    "r_thc = X_mo.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These Hamiltonian are exact molecular Hamiltonian and molecular Hamiltonian reconstructed by THC tensors. The calculation cost time, so that we store them in disk and load them when needed. For water molecule H2O in STO-6G basis, the error is small for r_THC = 28.\n",
    "\n",
    "Actually, considering there are always 10 electrons for a water molecule, we only retain the elements which operator quantum states with 10 electrons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load Hamiltonian generated by above coefficients\n",
    "#H_correct = scipy.io.mmread('/.mtx').tocsr()\n",
    "# e1, v1 = sparse.linalg.eigsh(H_correct, which = 'SA', k = 1)\n",
    "# e_ground = e1\n",
    "\n",
    "# H_correct_10e = generate_Hamiltonian_with_occupation_number(H_correct.real, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate THC-MPO by layers, using THC tensors. \n",
    "t_spin is used to create MPO for kinetic term.\n",
    "It returns a list of H_mu_nu, each H_mu_nu is also a list, which contains four smaller MPOs with bond dims 2.\n",
    "The final element of this list is MPO for kinetic term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate thc_mpo\n",
    "t_spin = get_t_spin(h1, eri)\n",
    "H_mu_nu_list_spin_layer = generate_thc_mpos_by_layer_qn(X_mo, Z_mo, L, t_spin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate elements in reduced Hamiltonian using conventional MPO.\n",
    "\n",
    "Since we only need to store ONE block during contraction, memory needed is only $\\mathcal{O}(L^2 M^2)$.\n",
    "\n",
    "Create conventional mpo for molecular Hamiltonian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 16, 39, 70, 87, 108, 133, 162, 195, 232, 195, 162, 133, 108, 87, 70, 39, 16, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "h1_spin = get_h1_spin(h1)\n",
    "g_spin = get_g_spin(eri)\n",
    "g_spin_phy =  g_spin.transpose(0, 2, 1, 3)\n",
    "mpo_ref = ptn.hamiltonian.molecular_hamiltonian_mpo(h1_spin, g_spin_phy)\n",
    "print(mpo_ref.bond_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ground state finding, we use Hatree fock state |11111111110000> as initial state.\n",
    "\n",
    "For 1st excited state, please use single-excited Hatree-Fock state as initial state, or even superposition of several single-excited Hatree-Fock states as initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1 = generate_single_state(20, [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "temp2 = generate_single_state(20, [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "temp3 = generate_single_state(20, [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "temp4 = generate_single_state(20, [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "hartree_state = add_mps(add_mps(add_mps(temp1, temp2), temp3),temp4)\n",
    "hartree_state.orthonormalize('right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate a group of orthogonal Krylov vectors using THC-MPO, with bond dim 40 for Krylov vectors. The vectors are stored in the folder = 'foldername', thus you don't have to generate them again for next time use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 4, 7, 11, 16, 22, 29, 37, 74, 120, 74, 37, 29, 22, 16, 11, 7, 4, 2, 1]\n",
      "2\n",
      "[1, 2, 4, 8, 16, 31, 57, 99, 163, 250, 250, 250, 163, 99, 57, 31, 16, 8, 4, 2, 1]\n",
      "3\n",
      "[1, 2, 4, 8, 16, 32, 63, 120, 189, 250, 250, 250, 187, 120, 63, 32, 16, 8, 4, 2, 1]\n",
      "4\n",
      "[1, 2, 4, 8, 16, 32, 63, 120, 188, 250, 250, 250, 188, 120, 63, 32, 16, 8, 4, 2, 1]\n",
      "5\n",
      "[1, 2, 4, 8, 16, 32, 63, 120, 188, 250, 250, 250, 188, 120, 63, 32, 16, 8, 4, 2, 1]\n",
      "6\n",
      "[1, 2, 4, 8, 16, 32, 63, 120, 188, 250, 250, 250, 188, 120, 63, 32, 16, 8, 4, 2, 1]\n",
      "7\n",
      "[1, 2, 4, 8, 16, 32, 63, 120, 188, 250, 250, 250, 188, 120, 63, 32, 16, 8, 4, 2, 1]\n",
      "8\n",
      "[1, 2, 4, 8, 16, 32, 63, 120, 188, 250, 250, 250, 188, 120, 63, 32, 16, 8, 4, 2, 1]\n",
      "9\n",
      "[1, 2, 4, 8, 16, 32, 63, 120, 188, 250, 250, 250, 188, 120, 63, 32, 16, 8, 4, 2, 1]\n",
      "10\n",
      "[1, 2, 4, 8, 16, 32, 63, 120, 188, 250, 250, 250, 188, 120, 63, 32, 16, 8, 4, 2, 1]\n",
      "11\n",
      "[1, 2, 4, 8, 16, 32, 63, 120, 188, 250, 250, 250, 188, 120, 63, 32, 16, 8, 4, 2, 1]\n",
      "12\n",
      "[1, 2, 4, 8, 16, 32, 63, 120, 188, 250, 250, 250, 188, 120, 63, 32, 16, 8, 4, 2, 1]\n",
      "13\n",
      "[1, 2, 4, 8, 16, 32, 63, 120, 188, 250, 250, 250, 188, 120, 63, 32, 16, 8, 4, 2, 1]\n",
      "14\n",
      "[1, 2, 4, 8, 16, 32, 63, 120, 188, 250, 250, 250, 188, 120, 63, 32, 16, 8, 4, 2, 1]\n",
      "15\n",
      "[1, 2, 4, 8, 16, 32, 63, 120, 188, 250, 250, 250, 188, 120, 63, 32, 16, 8, 4, 2, 1]\n",
      "16\n",
      "[1, 2, 4, 8, 16, 32, 63, 120, 188, 250, 250, 250, 188, 120, 63, 32, 16, 8, 4, 2, 1]\n",
      "17\n",
      "[1, 2, 4, 8, 16, 32, 63, 120, 188, 250, 250, 250, 188, 120, 63, 32, 16, 8, 4, 2, 1]\n",
      "18\n",
      "[1, 2, 4, 8, 16, 32, 63, 120, 188, 250, 250, 250, 188, 120, 63, 32, 16, 8, 4, 2, 1]\n",
      "19\n",
      "[1, 2, 4, 8, 16, 32, 63, 120, 188, 250, 250, 250, 188, 120, 63, 32, 16, 8, 4, 2, 1]\n",
      "20\n",
      "[1, 2, 4, 8, 16, 32, 63, 120, 188, 250, 250, 250, 188, 120, 63, 32, 16, 8, 4, 2, 1]\n",
      "21\n",
      "[1, 2, 4, 8, 16, 32, 63, 120, 188, 250, 250, 250, 188, 120, 63, 32, 16, 8, 4, 2, 1]\n",
      "22\n",
      "[1, 2, 4, 8, 16, 32, 63, 120, 188, 250, 250, 250, 188, 120, 63, 32, 16, 8, 4, 2, 1]\n",
      "23\n",
      "[1, 2, 4, 8, 16, 32, 63, 120, 188, 250, 250, 250, 188, 120, 63, 32, 16, 8, 4, 2, 1]\n",
      "24\n",
      "[1, 2, 4, 8, 16, 32, 64, 121, 190, 250, 250, 250, 190, 121, 64, 32, 16, 8, 4, 2, 1]\n",
      "25\n",
      "[1, 2, 4, 8, 16, 32, 64, 121, 190, 250, 250, 250, 190, 121, 64, 32, 16, 8, 4, 2, 1]\n",
      "26\n",
      "[1, 2, 4, 8, 16, 32, 64, 121, 190, 250, 250, 250, 190, 121, 64, 32, 16, 8, 4, 2, 1]\n",
      "27\n",
      "[1, 2, 4, 8, 16, 32, 64, 121, 190, 250, 250, 250, 192, 122, 64, 32, 16, 8, 4, 2, 1]\n",
      "28\n",
      "[1, 2, 4, 8, 16, 32, 64, 122, 192, 250, 250, 250, 192, 122, 64, 32, 16, 8, 4, 2, 1]\n",
      "29\n",
      "[1, 2, 4, 8, 16, 32, 64, 122, 193, 250, 250, 250, 193, 122, 64, 32, 16, 8, 4, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "N_Krylov = 30\n",
    "psi_original = copy.deepcopy(hartree_state)\n",
    "#max_bond_Krylov = 40\n",
    "max_bond_Krylov = 250\n",
    "trunc_tol = 0\n",
    "foldername = f\"/work_fast/ge49cag/code_datas/Krylov_H10_1st_ex\"\n",
    "#Krylov vectors are included in data, you dont have to run generate it. ofc, you can -regenerate it to verify the algorithm using the following code:\n",
    "\n",
    "generate_krylov_space_in_disk(N_Krylov, H_mu_nu_list_spin_layer, psi_original, max_bond_Krylov, trunc_tol, r_thc, foldername)\n",
    "#[1, 2, 4, 8, 16, 32, 63, 112, 176, 200, 200, 200, 180, 116, 63, 32, 16, 8, 4, 2, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make use of method proposed in https://journals.aps.org/prb/abstract/10.1103/PhysRevB.85.205119 to improve the orthogonality of Krylov vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work_fast/ge49cag/pytenet_thc/pytenet/global_krylov_method.py:193: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  H_reduced[i, j] = operator_inner_product(temp1, H_mpo, temp2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work_fast/ge49cag/pytenet_thc/pytenet/global_krylov_method.py:106: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  W[i,j] = np.vdot(temp1.as_vector(), temp2.as_vector())\n"
     ]
    }
   ],
   "source": [
    "N_use = 30\n",
    "# C = coeff_canonical_orthogonalization(N_use, foldername)\n",
    "# vector_list = generate_re_ortho_space_with_coeff(N_use, C, foldername)\n",
    "#vector_list = generate_re_ortho_space(N_use, foldername)\n",
    "H_reduced_non_rotho = generate_reduced_H_non_ortho(N_use, foldername, mpo_ref)\n",
    "W = get_W(N_use, foldername)\n",
    "coeff = get_S(W)\n",
    "coeff = np.array(coeff)\n",
    "#coeff = coeff_canonical_orthogonalization(N_use, foldername)\n",
    "#H_reduced: elements calculated by post-orthogonalized Krylov vectos\n",
    "H_reduced = np.einsum('ik, kl, jl -> ij', coeff.conj(), H_reduced_non_rotho, coeff)\n",
    "H_reduced = remain_only_tridiagonal_elements(H_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_list = [0]\n",
    "e_ground = -12.40719648\n",
    "mps_start = copy.deepcopy(hartree_state)\n",
    "error_list = [ptn.operation.operator_inner_product(mps_start, mpo_ref, mps_start) - e_ground]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.25341548]\n",
      "4.253418619118625\n",
      "[2.21874487]\n",
      "2.2188134371456325\n",
      "[1.45743916]\n",
      "1.4573803255012567\n",
      "[0.67800875]\n",
      "0.6780165368560755\n",
      "[0.29336667]\n",
      "0.2942693091280919\n",
      "[0.07952858]\n",
      "0.08156475585512801\n"
     ]
    }
   ],
   "source": [
    "for N in range(5, N_use+1, 5):\n",
    "    N_list.append(N)\n",
    "    H_part = H_reduced[:N, :N]\n",
    "    e_rotate, v_rotate = np.linalg.eigh(H_part)\n",
    "\n",
    "    #actually we need to orthogonalize the resulting vector to calculate the energy. A option could be add mps together and orthogonalize it.\n",
    "    v_rotate_ground_coeff = v_rotate[:,0] \n",
    "    temp = v_rotate[:,0]\n",
    "    temp = coeff[:N, :N].transpose(1,0)@temp\n",
    "    temp = H_reduced_non_rotho[:N, :N]@temp\n",
    "    temp = coeff[:N, :N].conj()@temp\n",
    "    e_rotate_ground = ((v_rotate[:,0].reshape(1, N)).conj())@temp\n",
    "    \n",
    "    print(e_rotate_ground - e_ground)\n",
    "    print(e_rotate[0] - e_ground)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "construct approx. ground vector (ritz vector) for re-start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ritz energy error: (0.07903326368608532+0j)\n"
     ]
    }
   ],
   "source": [
    "#assume N = N_use is the best solution\n",
    "C_ritz = ((v_rotate[:,0].reshape(N_use, 1)).transpose(1, 0))@ coeff\n",
    "C_ritz  = C_ritz.reshape(C_ritz.shape[1],)\n",
    "\n",
    "filename = foldername + f\"/Krylov_vec{0}.pkl\"\n",
    "with open(filename, 'rb') as file:\n",
    "    ritz_vec = pickle.load(file)\n",
    "ritz_vec.A[0] = C_ritz[0]* ritz_vec.A[0]\n",
    "        \n",
    "for i in range (1, N_use, 1):\n",
    "    filename = foldername + f\"/Krylov_vec{i}.pkl\"\n",
    "    with open(filename, 'rb') as file:\n",
    "        temp = pickle.load(file)\n",
    "    temp.A[0] = C_ritz[i]* temp.A[0]\n",
    "    ritz_vec = ptn.operation.add_mps_and_compress(ritz_vec, temp, 0, 200)\n",
    "\n",
    "ritz_vec.orthonormalize('right')\n",
    "e_ritz = ptn.operation.operator_average(ritz_vec, mpo_ref)\n",
    "print('ritz energy error:', e_ritz - e_ground)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 4, 8, 16, 32, 64, 126, 217, 250, 250, 250, 223, 127, 64, 32, 16, 8, 4, 2, 1]\n",
      "2\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 209, 250, 250, 250, 214, 127, 64, 32, 16, 8, 4, 2, 1]\n",
      "3\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 207, 250, 250, 250, 211, 127, 64, 32, 16, 8, 4, 2, 1]\n",
      "4\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 205, 250, 250, 250, 211, 127, 64, 32, 16, 8, 4, 2, 1]\n",
      "5\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 205, 250, 250, 250, 211, 127, 64, 32, 16, 8, 4, 2, 1]\n",
      "6\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 205, 250, 250, 250, 209, 126, 64, 32, 16, 8, 4, 2, 1]\n",
      "7\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 204, 250, 250, 250, 209, 126, 64, 32, 16, 8, 4, 2, 1]\n",
      "8\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 204, 250, 250, 250, 208, 126, 64, 32, 16, 8, 4, 2, 1]\n",
      "9\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 204, 250, 250, 250, 208, 126, 64, 32, 16, 8, 4, 2, 1]\n",
      "10\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 204, 250, 250, 250, 208, 126, 64, 32, 16, 8, 4, 2, 1]\n",
      "11\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 204, 250, 250, 250, 208, 126, 64, 32, 16, 8, 4, 2, 1]\n",
      "12\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 204, 250, 250, 250, 208, 126, 64, 32, 16, 8, 4, 2, 1]\n",
      "13\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 204, 250, 250, 250, 208, 126, 64, 32, 16, 8, 4, 2, 1]\n",
      "14\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 204, 250, 250, 250, 208, 126, 64, 32, 16, 8, 4, 2, 1]\n",
      "15\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 204, 250, 250, 250, 208, 126, 64, 32, 16, 8, 4, 2, 1]\n",
      "16\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 204, 250, 250, 250, 208, 126, 64, 32, 16, 8, 4, 2, 1]\n",
      "17\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 204, 250, 250, 250, 208, 126, 64, 32, 16, 8, 4, 2, 1]\n",
      "18\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 204, 250, 250, 250, 208, 126, 64, 32, 16, 8, 4, 2, 1]\n",
      "19\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 204, 250, 250, 250, 210, 127, 64, 32, 16, 8, 4, 2, 1]\n",
      "20\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 204, 250, 250, 250, 210, 127, 64, 32, 16, 8, 4, 2, 1]\n",
      "21\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 204, 250, 250, 250, 210, 127, 64, 32, 16, 8, 4, 2, 1]\n",
      "22\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 204, 250, 250, 250, 210, 127, 64, 32, 16, 8, 4, 2, 1]\n",
      "23\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 204, 250, 250, 250, 210, 127, 64, 32, 16, 8, 4, 2, 1]\n",
      "24\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'svd_small_count' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/work_fast/ge49cag/pytenet_thc/pytenet/operation_thc.py:82\u001b[0m, in \u001b[0;36mapply_thc_mpo_and_compress\u001b[0;34m(sub_H_list_as_layer, psi, trunc_tol, max_bond_global, r_THC)\u001b[0m\n\u001b[1;32m     81\u001b[0m     temp_mps \u001b[38;5;241m=\u001b[39m H_on_mps_compress_by_layer(temp_layers_mu, H_nu_psi, trunc_tol, max_bond_global)\n\u001b[0;32m---> 82\u001b[0m     H_on_psi \u001b[38;5;241m=\u001b[39m \u001b[43madd_mps_and_compress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH_on_psi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_mps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrunc_tol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bond_global\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m/work_fast/ge49cag/pytenet_thc/pytenet/operation.py:410\u001b[0m, in \u001b[0;36madd_mps_and_compress\u001b[0;34m(psi1, psi2, tol, max_bond_apply)\u001b[0m\n\u001b[1;32m    409\u001b[0m psi \u001b[38;5;241m=\u001b[39m add_mps(psi1, psi2)\n\u001b[0;32m--> 410\u001b[0m \u001b[43mpsi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress_no_normalization_max_bond\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_bond_apply\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m psi\n",
      "File \u001b[0;32m/work_fast/ge49cag/pytenet_thc/pytenet/mps.py:184\u001b[0m, in \u001b[0;36mMPS.compress_no_normalization_max_bond\u001b[0;34m(self, tol, mode, max_bond)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqD[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mlocal_orthonormalize_left_svd_max_bond\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mA\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mA\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqD\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m is_qsparse(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA[i], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqd, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqD[i], \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqD[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]]), \\\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparsity pattern of MPS tensor does not match quantum numbers\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/work_fast/ge49cag/pytenet_thc/pytenet/mps.py:454\u001b[0m, in \u001b[0;36mlocal_orthonormalize_left_svd_max_bond\u001b[0;34m(A, Anext, qd, qD, tol, max_bond)\u001b[0m\n\u001b[1;32m    453\u001b[0m q0 \u001b[38;5;241m=\u001b[39m qnumber_flatten([qd, qD[\u001b[38;5;241m0\u001b[39m]])\n\u001b[0;32m--> 454\u001b[0m U, sigma, V, qbond \u001b[38;5;241m=\u001b[39m \u001b[43msplit_matrix_svd_max_bond\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqD\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m A \u001b[38;5;241m=\u001b[39m U\u001b[38;5;241m.\u001b[39mreshape((s[\u001b[38;5;241m0\u001b[39m], s[\u001b[38;5;241m1\u001b[39m], U\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n",
      "File \u001b[0;32m/work_fast/ge49cag/pytenet_thc/pytenet/bond_ops_max_bond.py:187\u001b[0m, in \u001b[0;36msplit_matrix_svd_max_bond\u001b[0;34m(A, q0, q1, tol, max_bond)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# perform SVD decomposition of current block\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m usub, ssub, vsub \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi0\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj0\u001b[49m\u001b[43m:\u001b[49m\u001b[43mj1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# update intermediate dimension\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/linalg/linalg.py:1681\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1680\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->DdD\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->ddd\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1681\u001b[0m u, s, vh \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1682\u001b[0m u \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/linalg/linalg.py:121\u001b[0m, in \u001b[0;36m_raise_linalgerror_svd_nonconvergence\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_svd_nonconvergence\u001b[39m(err, flag):\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVD did not converge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: SVD did not converge",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m trunc_tol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      6\u001b[0m foldername_continue \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/work_fast/ge49cag/code_datas/Krylov_H10_1st_ex_restart\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mgenerate_krylov_space_in_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN_continue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH_mu_nu_list_spin_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsi_original_continue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bond_Krylov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrunc_tol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr_thc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfoldername_continue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work_fast/ge49cag/pytenet_thc/pytenet/global_krylov_method.py:61\u001b[0m, in \u001b[0;36mgenerate_krylov_space_in_disk\u001b[0;34m(N_Krylov, H_mu_nu_list_spin_layer, psi_original, max_bond_Krylov, trunc_tol, r_THC, foldername)\u001b[0m\n\u001b[1;32m     58\u001b[0m     orth_state2 \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m#first calculate H \\v_i\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m this_state \u001b[38;5;241m=\u001b[39m \u001b[43mapply_thc_mpo_and_compress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH_mu_nu_list_spin_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43morth_state2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrunc_tol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bond_Krylov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr_THC\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m this_state\u001b[38;5;241m.\u001b[39morthonormalize(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m#print(this_state.bond_dims)\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m#orthogonalize \"this state H \\v_i\" against the previous two”\u001b[39;00m\n",
      "File \u001b[0;32m/work_fast/ge49cag/pytenet_thc/pytenet/operation_thc.py:84\u001b[0m, in \u001b[0;36mapply_thc_mpo_and_compress\u001b[0;34m(sub_H_list_as_layer, psi, trunc_tol, max_bond_global, r_THC)\u001b[0m\n\u001b[1;32m     82\u001b[0m     H_on_psi \u001b[38;5;241m=\u001b[39m add_mps_and_compress(H_on_psi, temp_mps, trunc_tol, max_bond_global) \n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     svd_small_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mprint\u001b[39m(mu, nu, s1, s2)\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'svd_small_count' referenced before assignment"
     ]
    }
   ],
   "source": [
    "N_continue = 20\n",
    "psi_original_continue = copy.deepcopy(ritz_vec)\n",
    "#max_bond_Krylov = 40\n",
    "max_bond_Krylov = 250\n",
    "trunc_tol = 0\n",
    "foldername_continue = f\"/work_fast/ge49cag/code_datas/Krylov_H10_1st_ex_restart\"\n",
    "generate_krylov_space_in_disk(N_continue, H_mu_nu_list_spin_layer, psi_original_continue, max_bond_Krylov, trunc_tol, r_thc, foldername_continue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = coeff_canonical_orthogonalization(N_use, foldername)\n",
    "# vector_list = generate_re_ortho_space_with_coeff(N_use, C, foldername)\n",
    "#vector_list = generate_re_ortho_space(N_use, foldername)\n",
    "H_reduced_non_rotho_continue = generate_reduced_H_non_ortho(N_continue, foldername_continue, mpo_ref)\n",
    "W_continue = get_W(N_continue, foldername_continue)\n",
    "coeff_continue = get_S(W_continue)\n",
    "coeff_continue = np.array(coeff_continue) \n",
    "#coeff = coeff_canonical_orthogonalization(N_use, foldername)\n",
    "H_reduced_continue = np.einsum('ik, kl, jl -> ij', coeff_continue.conj(), H_reduced_non_rotho_continue, coeff_continue)\n",
    "H_reduced_continue = remain_only_tridiagonal_elements(H_reduced_continue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_continue_list = [0]\n",
    "continue_start = copy.deepcopy(ritz_vec)\n",
    "error_continue_list = [ptn.operation.operator_average(continue_start, mpo_ref) - e_ground]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04281986]\n",
      "0.0477590275591524\n",
      "[0.01472843]\n",
      "0.021884522336053536\n",
      "[0.01266539]\n",
      "0.020378321370438712\n",
      "[0.01242435]\n",
      "0.020259829625061343\n",
      "[0.01232799]\n",
      "0.020255757668323326\n",
      "[0.01227127]\n",
      "0.02025550992326508\n",
      "[0.0122629]\n",
      "0.020255504587401774\n",
      "[0.01226254]\n",
      "0.02025550456433045\n"
     ]
    }
   ],
   "source": [
    "for N in range(5, N_continue+1, 5):\n",
    "    N_continue_list.append(N)\n",
    "    H_part_continue = H_reduced_continue[:N, :N]\n",
    "    e_rotate_continue, v_rotate_continue = np.linalg.eigh(H_part_continue)\n",
    "\n",
    "    #actually we need to orthogonalize the resulting vector to calculate the energy. A option could be add mps together and orthogonalize it.\n",
    "    v_rotate_ground_coeff_continue = v_rotate_continue[:,0] \n",
    "    temp = v_rotate_continue[:,0]\n",
    "    temp = coeff_continue[:N, :N].transpose(1,0)@temp\n",
    "    temp = H_reduced_non_rotho_continue[:N, :N]@temp\n",
    "    temp = coeff_continue[:N, :N].conj()@temp\n",
    "    e_rotate_ground_continue = ((v_rotate_continue[:,0].reshape(1, N)).conj())@temp\n",
    "    error_continue_list.append(e_rotate_ground_continue - e_ground)\n",
    "    \n",
    "    print(e_rotate_ground_continue - e_ground)\n",
    "    print(e_rotate_continue[0] - e_ground)\n",
    "    #it looks like orthogonal issue\n",
    "    #上面两个一样吗？\n",
    "    #必须要加MPS再normalize吗？\n",
    "    #check how lanczos in numpy do orthogonaliztion. Ask ppl in the chair?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ritz energy error: (0.00951894483580773+0j)\n"
     ]
    }
   ],
   "source": [
    "#assume N = N_use is the best solution\n",
    "C_ritz_continue = ((v_rotate_continue[:,0].reshape(N_continue, 1)).transpose(1, 0))@ coeff_continue\n",
    "C_ritz_continue  = C_ritz_continue.reshape(C_ritz_continue.shape[1],)\n",
    "\n",
    "filename = foldername_continue + f\"/Krylov_vec{0}.pkl\"\n",
    "with open(filename, 'rb') as file:\n",
    "    ritz_vec_continue = pickle.load(file)\n",
    "ritz_vec_continue.A[0] = C_ritz_continue[0]* ritz_vec_continue.A[0]\n",
    "        \n",
    "for i in range (1, N_continue, 1):\n",
    "    filename = foldername_continue + f\"/Krylov_vec{i}.pkl\"\n",
    "    with open(filename, 'rb') as file:\n",
    "        temp = pickle.load(file)\n",
    "    temp.A[0] = C_ritz_continue[i]* temp.A[0]\n",
    "    ritz_vec_continue = ptn.operation.add_mps_and_compress(ritz_vec_continue, temp, 0, 200)\n",
    "\n",
    "ritz_vec_continue.orthonormalize('right')\n",
    "e_ritz_continue = ptn.operation.operator_average(ritz_vec_continue, mpo_ref)\n",
    "print('ritz energy error:', e_ritz_continue - e_ground)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 4, 8, 16, 32, 64, 123, 189, 200, 200, 200, 195, 125, 64, 32, 16, 8, 4, 2, 1]\n",
      "2\n",
      "[1, 2, 4, 8, 16, 32, 64, 124, 194, 200, 200, 200, 197, 125, 64, 32, 16, 8, 4, 2, 1]\n",
      "3\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 196, 200, 200, 200, 198, 125, 64, 32, 16, 8, 4, 2, 1]\n",
      "4\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 197, 200, 200, 200, 199, 125, 64, 32, 16, 8, 4, 2, 1]\n",
      "5\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 197, 200, 200, 200, 199, 125, 64, 32, 16, 8, 4, 2, 1]\n",
      "6\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 197, 200, 200, 200, 199, 125, 64, 32, 16, 8, 4, 2, 1]\n",
      "7\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 197, 200, 200, 200, 199, 125, 64, 32, 16, 8, 4, 2, 1]\n",
      "8\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 197, 200, 200, 200, 199, 125, 64, 32, 16, 8, 4, 2, 1]\n",
      "9\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 197, 200, 200, 200, 199, 125, 64, 32, 16, 8, 4, 2, 1]\n",
      "10\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 197, 200, 200, 200, 199, 125, 64, 32, 16, 8, 4, 2, 1]\n",
      "11\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 197, 200, 200, 200, 199, 125, 64, 32, 16, 8, 4, 2, 1]\n",
      "12\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 197, 200, 200, 200, 200, 126, 64, 32, 16, 8, 4, 2, 1]\n",
      "13\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 197, 200, 200, 200, 200, 126, 64, 32, 16, 8, 4, 2, 1]\n",
      "14\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 197, 200, 200, 200, 200, 126, 64, 32, 16, 8, 4, 2, 1]\n",
      "15\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 197, 200, 200, 200, 200, 126, 64, 32, 16, 8, 4, 2, 1]\n",
      "16\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 197, 200, 200, 200, 200, 126, 64, 32, 16, 8, 4, 2, 1]\n",
      "17\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 197, 200, 200, 200, 200, 126, 64, 32, 16, 8, 4, 2, 1]\n",
      "18\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 197, 200, 200, 200, 198, 125, 64, 32, 16, 8, 4, 2, 1]\n",
      "19\n",
      "[1, 2, 4, 8, 16, 32, 64, 125, 197, 200, 200, 200, 198, 125, 64, 32, 16, 8, 4, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "N_continue_a = 30\n",
    "psi_original_continue_a = copy.deepcopy(ritz_vec_continue)\n",
    "#max_bond_Krylov = 40\n",
    "max_bond_Krylov = 250\n",
    "trunc_tol = 0\n",
    "foldername_continue_a = f\"/work_fast/ge49cag/code_datas/Krylov_H10_1st_ex_restart_a\"\n",
    "generate_krylov_space_in_disk(N_continue_a, H_mu_nu_list_spin_layer, psi_original_continue_a, max_bond_Krylov, trunc_tol, r_thc, foldername_continue_a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work_fast/ge49cag/pytenet_thc/pytenet/global_krylov_method.py:193: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  H_reduced[i, j] = operator_inner_product(temp1, H_mpo, temp2)\n",
      "/work_fast/ge49cag/pytenet_thc/pytenet/global_krylov_method.py:106: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  W[i,j] = np.vdot(temp1.as_vector(), temp2.as_vector())\n"
     ]
    }
   ],
   "source": [
    "H_reduced_non_rotho_continue_a = generate_reduced_H_non_ortho(N_continue_a, foldername_continue_a, mpo_ref)\n",
    "W_continue_a = get_W(N_continue_a, foldername_continue_a)\n",
    "coeff_continue_a = get_S(W_continue_a)\n",
    "coeff_continue_a = np.array(coeff_continue_a) \n",
    "#coeff = coeff_canonical_orthogonalization(N_use, foldername)\n",
    "H_reduced_continue_a = np.einsum('ik, kl, jl -> ij', coeff_continue_a.conj(), H_reduced_non_rotho_continue_a, coeff_continue_a)\n",
    "H_reduced_continue_a = remain_only_tridiagonal_elements(H_reduced_continue_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ritz energy error: (0.0016169623488675455+0j)\n"
     ]
    }
   ],
   "source": [
    "e_rotate_continue_a, v_rotate_continue_a = np.linalg.eigh(H_reduced_continue_a)\n",
    "\n",
    "\n",
    "\n",
    "C_ritz_continue_a = ((v_rotate_continue_a[:,0].reshape(N_continue_a, 1)).transpose(1, 0))@ coeff_continue_a\n",
    "C_ritz_continue_a  = C_ritz_continue_a.reshape(C_ritz_continue_a.shape[1],)\n",
    "\n",
    "filename = foldername_continue_a + f\"/Krylov_vec{0}.pkl\"\n",
    "with open(filename, 'rb') as file:\n",
    "    ritz_vec_continue_a = pickle.load(file)\n",
    "ritz_vec_continue_a.A[0] = C_ritz_continue_a[0]* ritz_vec_continue_a.A[0]\n",
    "        \n",
    "for i in range (1, N_continue_a, 1):\n",
    "    filename = foldername_continue_a + f\"/Krylov_vec{i}.pkl\"\n",
    "    with open(filename, 'rb') as file:\n",
    "        temp = pickle.load(file)\n",
    "    temp.A[0] = C_ritz_continue_a[i]* temp.A[0]\n",
    "    ritz_vec_continue_a = ptn.operation.add_mps_and_compress(ritz_vec_continue_a, temp, 0, 200)\n",
    "\n",
    "ritz_vec_continue_a.orthonormalize('right')\n",
    "e_ritz_continue_a = ptn.operation.operator_average(ritz_vec_continue_a, mpo_ref)\n",
    "print('ritz energy error:', e_ritz_continue_a - e_ground)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To do: \n",
    "#max-bond 设置为250\n",
    "#每步30， 一共restart三次\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
