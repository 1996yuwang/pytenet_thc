{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pytenet.hartree_fock_mps import generate_single_state\n",
    "from pytenet.hamiltonian_thc import eval_func, generate_thc_mpos_by_layer_qn, get_t_spin\n",
    "from pytenet.global_krylov_method import generate_krylov_space_in_disk, get_W, get_S, generate_re_ortho_space, generate_reduced_H, generate_Hamiltonian_with_occupation_number\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import copy\n",
    "import h5py\n",
    "from numpy.linalg import norm\n",
    "#np.set_printoptions(precision=4,suppress=True)\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and initialize datas: \n",
    "\n",
    "no is number of spatial orbitals\n",
    "\n",
    "L is number of spinor orbitals, L = 2*no\n",
    "\n",
    "t_spin is one-body integral in Chemist's notation (considering spins)\n",
    "\n",
    "g_spin is two-body integral in Chemist's notation (considering spins)\n",
    "\n",
    "X_mo and Z_mo are THC tensors, X_mo_up/down are X_mo considering spins\n",
    "\n",
    "r_THC is THC rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "(7, 28)\n",
      "(28, 28)\n",
      "rl errV: 2.8386751875274264e-12\n",
      "abs errV: 2.0615721155266396e-11\n",
      "errt: 7.097049412242525e-13\n",
      "errh: 2.585427402664151e-13\n",
      "errht: 9.079449636842276e-14\n"
     ]
    }
   ],
   "source": [
    "#load integrals\n",
    "with h5py.File(\"data_water/eri_water.hdf5\", \"r\") as f:\n",
    "#with h5py.File(\"/work_fast/ge49cag/pytenet_yu/water/eri_water.hdf5\", \"r\") as f:\n",
    "    eri = f[\"eri\"][()]\n",
    "    hkin = f[\"hkin\"][()]\n",
    "    hnuc = f[\"hnuc\"][()]\n",
    "\n",
    "#print(np.linalg.norm(eri))\n",
    "#print(eri.shape)\n",
    "\n",
    "no = eri.shape[0]\n",
    "MV = eri.reshape(no*no,no*no)\n",
    "\n",
    "u = np.load(\"data_water/x.npy\")\n",
    "#u = np.load(\"/work_fast/ge49cag/pytenet_yu/water/x.npy\")\n",
    "X_mo = u.transpose(1,0)\n",
    "g_thc, Z_mo = eval_func(u,eri,hkin,hnuc,)\n",
    "h1 = hnuc+hkin\n",
    "nmo = X_mo.shape[1]\n",
    "L = 2*X_mo.shape[1]\n",
    "g_thc = g_thc.reshape(nmo, nmo, nmo, nmo)\n",
    "r_thc = X_mo.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These Hamiltonian are exact molecular Hamiltonian and molecular Hamiltonian reconstructed by THC tensors. The calculation cost time, so that we store them in disk and load them when needed. For water molecule H2O in STO-6G basis, the error is small for r_THC = 28.\n",
    "\n",
    "Actually, considering there are always 10 electrons for a water molecule, we only retain the elements which operator quantum states with 10 electrons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ge49cag/.local/lib/python3.10/site-packages/scipy/sparse/_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "#load Hamiltonian generated by above coefficients\n",
    "H_correct = scipy.io.mmread('data_water/H_water_correct.mtx').tocsr()\n",
    "e1, v1 = sparse.linalg.eigsh(H_correct, which = 'SA', k = 1)\n",
    "e_ground = e1\n",
    "\n",
    "H_correct_10e = generate_Hamiltonian_with_occupation_number(H_correct.real, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate THC-MPO by layers, using THC tensors. \n",
    "t_spin is used to create MPO for kinetic term.\n",
    "It returns a list of H_mu_nu, each H_mu_nu is also a list, which contains four smaller MPOs with bond dims 2.\n",
    "The final element of this list is MPO for kinetic term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'pytenet.mpo.MPO'>\n",
      "[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "#generate thc_mpo\n",
    "t_spin = get_t_spin(h1, eri)\n",
    "H_mu_nu_list_spin_layer = generate_thc_mpos_by_layer_qn(X_mo, Z_mo, L, t_spin)\n",
    "\n",
    "print(type(H_mu_nu_list_spin_layer))\n",
    "print(type(H_mu_nu_list_spin_layer[0]))\n",
    "print(type(H_mu_nu_list_spin_layer[0][0]))\n",
    "print((H_mu_nu_list_spin_layer[0][0].bond_dims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ground state finding, we use Hatree fock state |11111111110000> as initial state.\n",
    "\n",
    "For 1st excited state, please use single-excited Hatree-Fock state as initial state, or even superposition of several single-excited Hatree-Fock states as initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hartree_state = generate_single_state(14, [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0])\n",
    "hartree_state_vector = hartree_state.as_vector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate a group of orthogonal Krylov vectors using THC-MPO, with bond dim 40 for Krylov vectors. The vectors are stored in the folder = 'foldername', thus you don't have to generate them again for next time use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 4, 7, 11, 12, 13, 14, 15, 16, 11, 7, 4, 2, 1]\n",
      "2\n",
      "[1, 2, 4, 8, 16, 26, 31, 37, 31, 26, 16, 8, 4, 2, 1]\n",
      "3\n",
      "[1, 2, 4, 8, 16, 26, 31, 37, 31, 26, 16, 8, 4, 2, 1]\n",
      "4\n",
      "[1, 2, 4, 8, 16, 26, 31, 37, 31, 26, 16, 8, 4, 2, 1]\n",
      "5\n",
      "[1, 2, 4, 8, 16, 26, 31, 37, 31, 26, 16, 8, 4, 2, 1]\n",
      "6\n",
      "[1, 2, 4, 8, 16, 26, 31, 37, 31, 26, 16, 8, 4, 2, 1]\n",
      "7\n",
      "[1, 2, 4, 8, 16, 26, 31, 37, 31, 26, 16, 8, 4, 2, 1]\n",
      "8\n",
      "[1, 2, 4, 8, 16, 26, 31, 37, 31, 26, 16, 8, 4, 2, 1]\n",
      "9\n",
      "[1, 2, 4, 8, 16, 26, 31, 37, 31, 26, 16, 8, 4, 2, 1]\n",
      "10\n",
      "[1, 2, 4, 8, 16, 26, 31, 37, 31, 26, 16, 8, 4, 2, 1]\n",
      "11\n",
      "[1, 2, 4, 8, 16, 26, 31, 37, 31, 26, 16, 8, 4, 2, 1]\n",
      "12\n",
      "[1, 2, 4, 8, 16, 26, 31, 37, 31, 26, 16, 8, 4, 2, 1]\n",
      "13\n",
      "[1, 2, 4, 8, 16, 26, 31, 37, 31, 26, 16, 8, 4, 2, 1]\n",
      "14\n",
      "[1, 2, 4, 8, 16, 26, 31, 37, 31, 26, 16, 8, 4, 2, 1]\n",
      "15\n",
      "[1, 2, 4, 8, 16, 26, 31, 37, 31, 26, 16, 8, 4, 2, 1]\n",
      "16\n",
      "[1, 2, 4, 8, 16, 26, 31, 37, 31, 26, 16, 8, 4, 2, 1]\n",
      "17\n",
      "[1, 2, 4, 8, 16, 26, 31, 37, 31, 26, 16, 8, 4, 2, 1]\n",
      "18\n",
      "[1, 2, 4, 8, 16, 26, 31, 37, 31, 26, 16, 8, 4, 2, 1]\n",
      "19\n",
      "[1, 2, 4, 8, 16, 26, 31, 37, 31, 26, 16, 8, 4, 2, 1]\n",
      "20\n",
      "[1, 2, 4, 8, 16, 26, 31, 37, 31, 26, 16, 8, 4, 2, 1]\n",
      "21\n",
      "[1, 2, 4, 8, 16, 26, 31, 37, 31, 26, 16, 8, 4, 2, 1]\n",
      "22\n",
      "[1, 2, 4, 8, 16, 26, 31, 37, 31, 26, 16, 8, 4, 2, 1]\n",
      "23\n",
      "[1, 2, 4, 8, 16, 26, 31, 37, 31, 26, 16, 8, 4, 2, 1]\n",
      "24\n",
      "[1, 2, 4, 8, 16, 26, 31, 37, 31, 26, 16, 8, 4, 2, 1]\n",
      "25\n",
      "[1, 2, 4, 8, 16, 26, 31, 37, 31, 26, 16, 8, 4, 2, 1]\n",
      "26\n",
      "[1, 2, 4, 8, 16, 26, 31, 37, 31, 26, 16, 8, 4, 2, 1]\n",
      "27\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m foldername \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwater_Krylov\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#Krylov vectors are included in data, you dont have to run generate it. ofc, you can -regenerate it to verify the algorithm using the following code:\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mgenerate_krylov_space_in_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN_Krylov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH_mu_nu_list_spin_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsi_original\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bond_Krylov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrunc_tol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr_thc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfoldername\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# it indicates that even though during the calculation the bond dims exceed 40, but we only need 37 for Krylov vectors.\u001b[39;00m\n",
      "File \u001b[0;32m/work_fast/ge49cag/pytenet_thc/pytenet/global_krylov_method.py:61\u001b[0m, in \u001b[0;36mgenerate_krylov_space_in_disk\u001b[0;34m(N_Krylov, H_mu_nu_list_spin_layer, psi_original, max_bond_Krylov, trunc_tol, r_THC, foldername)\u001b[0m\n\u001b[1;32m     58\u001b[0m     orth_state2 \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m#first calculate H \\v_i\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m this_state \u001b[38;5;241m=\u001b[39m \u001b[43mapply_thc_mpo_and_compress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH_mu_nu_list_spin_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43morth_state2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrunc_tol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bond_Krylov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr_THC\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m this_state\u001b[38;5;241m.\u001b[39morthonormalize(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m#print(this_state.bond_dims)\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m#orthogonalize \"this state H \\v_i\" against the previous twoâ€\u001b[39;00m\n",
      "File \u001b[0;32m/work_fast/ge49cag/pytenet_thc/pytenet/operation_thc.py:82\u001b[0m, in \u001b[0;36mapply_thc_mpo_and_compress\u001b[0;34m(sub_H_list_as_layer, psi, trunc_tol, max_bond_global, r_THC)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     temp_mps \u001b[38;5;241m=\u001b[39m H_on_mps_compress_by_layer(temp_layers_mu, H_nu_psi, trunc_tol, max_bond_global)\n\u001b[0;32m---> 82\u001b[0m     H_on_psi \u001b[38;5;241m=\u001b[39m \u001b[43madd_mps_and_compress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH_on_psi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_mps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrunc_tol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bond_global\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m     svd_small_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/work_fast/ge49cag/pytenet_thc/pytenet/operation.py:410\u001b[0m, in \u001b[0;36madd_mps_and_compress\u001b[0;34m(psi1, psi2, tol, max_bond_apply)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;124;03mAdd two MPS, and then compress it, with tol and maximum bond dims.\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;124;03mSee ptn.mps.local_orthonormalize_right_svd_max_bond for compression details.\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    409\u001b[0m psi \u001b[38;5;241m=\u001b[39m add_mps(psi1, psi2)\n\u001b[0;32m--> 410\u001b[0m \u001b[43mpsi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress_no_normalization_max_bond\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_bond_apply\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m psi\n",
      "File \u001b[0;32m/work_fast/ge49cag/pytenet_thc/pytenet/mps.py:180\u001b[0m, in \u001b[0;36mMPS.compress_no_normalization_max_bond\u001b[0;34m(self, tol, mode, max_bond)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03mThis compression doesn't work with normalized MPS. Mainly used for H|\\psi> calculation, which is not normalzied.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03mAttention: the tol here works on normalized matrix, thus the final error will be scaled by nrm!\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# transform to right-canonical form first\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     nrm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morthonormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mright\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;66;03m# cancel the normalization in this step:\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m nrm\u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/work_fast/ge49cag/pytenet_thc/pytenet/mps.py:112\u001b[0m, in \u001b[0;36mMPS.orthonormalize\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA))):\n\u001b[0;32m--> 112\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqD[i] \u001b[38;5;241m=\u001b[39m \u001b[43mlocal_orthonormalize_right_qr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mA\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mA\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqD\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# first tensor\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA[\u001b[38;5;241m0\u001b[39m], T, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqD[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m local_orthonormalize_right_qr(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA[\u001b[38;5;241m0\u001b[39m], np\u001b[38;5;241m.\u001b[39marray([[[\u001b[38;5;241m1\u001b[39m]]]), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqd, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqD[:\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m/work_fast/ge49cag/pytenet_thc/pytenet/mps.py:305\u001b[0m, in \u001b[0;36mlocal_orthonormalize_right_qr\u001b[0;34m(A, Aprev, qd, qD)\u001b[0m\n\u001b[1;32m    303\u001b[0m q0 \u001b[38;5;241m=\u001b[39m qnumber_flatten([qd, \u001b[38;5;241m-\u001b[39mqD[\u001b[38;5;241m1\u001b[39m]])\n\u001b[1;32m    304\u001b[0m Q, R, qbond \u001b[38;5;241m=\u001b[39m qr(A\u001b[38;5;241m.\u001b[39mreshape((s[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39ms[\u001b[38;5;241m1\u001b[39m], s[\u001b[38;5;241m2\u001b[39m])), q0, \u001b[38;5;241m-\u001b[39mqD[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 305\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[43mQ\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# update Aprev tensor: multiply with R from right\u001b[39;00m\n\u001b[1;32m    307\u001b[0m Aprev \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtensordot(Aprev, R, (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_Krylov = 50\n",
    "psi_original = copy.deepcopy(hartree_state)\n",
    "#max_bond_Krylov = 40\n",
    "max_bond_Krylov = 75\n",
    "trunc_tol = 0\n",
    "foldername = f\"water_Krylov\"\n",
    "#Krylov vectors are included in data, you dont have to run generate it. ofc, you can -regenerate it to verify the algorithm using the following code:\n",
    "\n",
    "#generate_krylov_space_in_disk(N_Krylov, H_mu_nu_list_spin_layer, psi_original, max_bond_Krylov, trunc_tol, r_thc, foldername)\n",
    "\n",
    "# it indicates that even though during the calculation the bond dims exceed 40, but we only need 37 for Krylov vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make use of method proposed in https://journals.aps.org/prb/abstract/10.1103/PhysRevB.85.205119 to improve the orthogonality of Krylov vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work_fast/ge49cag/pytenet_thc/pytenet/global_krylov_method.py:106: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  W[i,j] = np.vdot(temp1.as_vector(), temp2.as_vector())\n"
     ]
    }
   ],
   "source": [
    "W = get_W(N_Krylov, foldername)\n",
    "S = get_S(W)\n",
    "vector_list = generate_re_ortho_space(N_Krylov, W, foldername)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After achieving Krylov vectors, we implement Lanczos algorithm using these Krylov vectors. In this notebook, all the expectation values are calculated using ED for convenience. Since calculating the expectation value (contracting the tensor network) doesn't bring new errors, it makes no difference whether we use tensor network or ED to calculate the matrix elements for reduced Hamiltonian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work_fast/ge49cag/pytenet_thc/pytenet/global_krylov_method.py:173: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  H_reduced[i, j] = np.vdot(vector_list[i], H@vector_list[j])\n"
     ]
    }
   ],
   "source": [
    "H_reduced = generate_reduced_H(vector_list, H_correct_10e)\n",
    "N_list = [0]\n",
    "mps_start = copy.deepcopy(hartree_state)\n",
    "error_list = [np.vdot(mps_start.as_vector(), H_correct_10e@(mps_start.as_vector())) - e_ground]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35244435+0.j]\n",
      "[0.02484897+0.j]\n",
      "[0.00195854+0.j]\n",
      "[7.230799e-05+0.j]\n",
      "[8.51511174e-07+0.j]\n"
     ]
    }
   ],
   "source": [
    "for N in range(5, N_Krylov+1, 5):\n",
    "    N_list.append(N)\n",
    "    H_part = H_reduced[:N, :N]\n",
    "    e_rotate, v_rotate = np.linalg.eigh(H_part)\n",
    "\n",
    "    v_rotate_ground = v_rotate[:,0][0]* vector_list[0]\n",
    "    for i in range (1, N):\n",
    "        v_rotate_ground += v_rotate[:,0][i]* vector_list[i]\n",
    "    v_rotate_ground /= norm(v_rotate_ground)\n",
    "    e_new = np.vdot(v_rotate_ground, H_correct_10e@v_rotate_ground)\n",
    "    error_list.append(e_new - e_ground)\n",
    "    \n",
    "    print(e_new - e_ground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
