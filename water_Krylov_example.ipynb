{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pytenet.hartree_fock_mps import generate_single_state\n",
    "from pytenet.hamiltonian_thc import eval_func, generate_thc_mpos_by_layer_qn, get_t_spin\n",
    "from pytenet.fermi_ops import generate_fermi_operators\n",
    "from pytenet.operation_thc import H_on_mps_compress_by_layer, apply_thc_mpo_and_compress, generate_krylov_space_in_disk, get_W, get_S, generate_re_ortho_space, generate_reduced_H, generate_Hamiltonian_with_occupation_number\n",
    "from pytenet.operation import apply_operator_and_compress\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import copy\n",
    "import pytenet as ptn\n",
    "import h5py\n",
    "from numpy.linalg import norm\n",
    "#np.set_printoptions(precision=4,suppress=True)\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and initialize datas: \n",
    "\n",
    "no is number of spatial orbitals\n",
    "\n",
    "L is number of spinor orbitals, L = 2*no\n",
    "\n",
    "t_spin is one-body integral in Chemist's notation (considering spins)\n",
    "\n",
    "g_spin is two-body integral in Chemist's notation (considering spins)\n",
    "\n",
    "X_mo and Z_mo are THC tensors, X_mo_up/down are X_mo considering spins\n",
    "\n",
    "r_THC is THC rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "(7, 28)\n",
      "(28, 28)\n",
      "rl errV: 2.8386751875274264e-12\n",
      "abs errV: 2.0615721155266396e-11\n",
      "errt: 7.097049412242525e-13\n",
      "errh: 2.585427402664151e-13\n",
      "errht: 9.079449636842276e-14\n"
     ]
    }
   ],
   "source": [
    "#load integrals\n",
    "with h5py.File(\"data_water/eri_water.hdf5\", \"r\") as f:\n",
    "#with h5py.File(\"/work_fast/ge49cag/pytenet_yu/water/eri_water.hdf5\", \"r\") as f:\n",
    "    eri = f[\"eri\"][()]\n",
    "    hkin = f[\"hkin\"][()]\n",
    "    hnuc = f[\"hnuc\"][()]\n",
    "\n",
    "#print(np.linalg.norm(eri))\n",
    "#print(eri.shape)\n",
    "\n",
    "no = eri.shape[0]\n",
    "MV = eri.reshape(no*no,no*no)\n",
    "\n",
    "u = np.load(\"data_water/x.npy\")\n",
    "#u = np.load(\"/work_fast/ge49cag/pytenet_yu/water/x.npy\")\n",
    "X_mo = u.transpose(1,0)\n",
    "g_thc, Z_mo = eval_func(u,eri,hkin,hnuc,)\n",
    "h1 = hnuc+hkin\n",
    "nmo = X_mo.shape[1]\n",
    "L = 2*X_mo.shape[1]\n",
    "g_thc = g_thc.reshape(nmo, nmo, nmo, nmo)\n",
    "r_thc = X_mo.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These Hamiltonian are exact molecular Hamiltonian and molecular Hamiltonian reconstructed by THC tensors. The calculation cost time, so that we store them in disk and load them when needed. For water molecule H2O in STO-6G basis, the error is small for r_THC = 28.\n",
    "\n",
    "Actually, considering there are always 10 electrons for a water molecule, we only retain the elements which operator quantum states with 10 electrons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ge49cag/.local/lib/python3.10/site-packages/scipy/sparse/_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "#load Hamiltonian generated by above coefficients\n",
    "H_correct = scipy.io.mmread('data_water/H_water_correct.mtx').tocsr()\n",
    "e1, v1 = sparse.linalg.eigsh(H_correct, which = 'SA', k = 1)\n",
    "e_ground = e1\n",
    "\n",
    "H_correct_10e = generate_Hamiltonian_with_occupation_number(H_correct.real, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate THC-MPO by layers, using THC tensors. \n",
    "t_spin is used to create MPO for kinetic term.\n",
    "It returns a list of H_mu_nu, each H_mu_nu is also a list, which contains four smaller MPOs with bond dims 2.\n",
    "The final element of this list is MPO for kinetic term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'pytenet.mpo.MPO'>\n",
      "[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "#generate thc_mpo\n",
    "t_spin = get_t_spin(h1, eri)\n",
    "H_mu_nu_list_spin_layer = generate_thc_mpos_by_layer_qn(X_mo, Z_mo, L, t_spin)\n",
    "\n",
    "print(type(H_mu_nu_list_spin_layer))\n",
    "print(type(H_mu_nu_list_spin_layer[0]))\n",
    "print(type(H_mu_nu_list_spin_layer[0][0]))\n",
    "print((H_mu_nu_list_spin_layer[0][0].bond_dims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ground state finding, we use Hatree fock state |11111111110000> as initial state.\n",
    "\n",
    "For 1st excited state, please use single-excited Hatree-Fock state as initial state, or even superposition of several single-excited Hatree-Fock states as initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hartree_state = generate_single_state(14, [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0])\n",
    "hartree_state_vector = hartree_state.as_vector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate a group of orthogonal Krylov vectors using THC-MPO, with bond dim 40 for Krylov vectors. The vectors are stored in the folder = 'foldername', thus you don't have to generate them again for next time use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 4, 7, 11, 12, 13, 14, 15, 16, 11, 7, 4, 2, 1]\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m foldername \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_water_new\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#Krylov vectors are included in data, you dont have to run generate it. ofc, you can -regenerate it to verify the algorithm using the following code:\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mgenerate_krylov_space_in_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN_Krylov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH_mu_nu_list_spin_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsi_original\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bond_Krylov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrunc_tol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr_thc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfoldername\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work_fast/ge49cag/pytenet_thc/pytenet/operation_thc.py:170\u001b[0m, in \u001b[0;36mgenerate_krylov_space_in_disk\u001b[0;34m(N_Krylov, H_mu_nu_list_spin_layer, psi_original, max_bond_Krylov, trunc_tol, r_THC, foldername)\u001b[0m\n\u001b[1;32m    167\u001b[0m     orth_state2 \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m#first calculate H \\v_i\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m this_state \u001b[38;5;241m=\u001b[39m \u001b[43mapply_thc_mpo_and_compress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH_mu_nu_list_spin_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43morth_state2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrunc_tol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bond_Krylov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr_THC\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m this_state\u001b[38;5;241m.\u001b[39morthonormalize(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28mprint\u001b[39m(this_state\u001b[38;5;241m.\u001b[39mbond_dims)\n",
      "File \u001b[0;32m/work_fast/ge49cag/pytenet_thc/pytenet/operation_thc.py:83\u001b[0m, in \u001b[0;36mapply_thc_mpo_and_compress\u001b[0;34m(sub_H_list_as_layer, psi, trunc_tol, max_bond_global, r_THC)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m     temp_mps \u001b[38;5;241m=\u001b[39m H_on_mps_compress_by_layer(temp_layers_mu, H_nu_psi, trunc_tol, max_bond_global)\n\u001b[0;32m---> 83\u001b[0m     H_on_psi \u001b[38;5;241m=\u001b[39m \u001b[43madd_mps_and_compress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH_on_psi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_mps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrunc_tol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bond_global\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m     85\u001b[0m     svd_small_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/work_fast/ge49cag/pytenet_thc/pytenet/operation.py:409\u001b[0m, in \u001b[0;36madd_mps_and_compress\u001b[0;34m(psi1, psi2, tol, max_bond_apply)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_mps_and_compress\u001b[39m(psi1: MPS, psi2: MPS, tol, max_bond_apply):\n\u001b[1;32m    404\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;124;03m    Add two MPS, and then compress it, with tol and maximum bond dims.\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;124;03m    See ptn.mps.local_orthonormalize_right_svd_max_bond for compression details.\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m     psi \u001b[38;5;241m=\u001b[39m \u001b[43madd_mps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpsi1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsi2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m     psi\u001b[38;5;241m.\u001b[39mcompress_no_normalization_max_bond(tol, max_bond \u001b[38;5;241m=\u001b[39m max_bond_apply)\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m psi\n",
      "File \u001b[0;32m/work_fast/ge49cag/pytenet_thc/pytenet/mps.py:440\u001b[0m, in \u001b[0;36madd_mps\u001b[0;34m(mps0, mps1, alpha)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;66;03m# consistency check\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, L):\n\u001b[0;32m--> 440\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mis_qsparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mA\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqD\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mmps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqD\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, \\\n\u001b[1;32m    441\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparsity pattern of MPS tensor does not match quantum numbers\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mps\n",
      "File \u001b[0;32m/work_fast/ge49cag/pytenet_thc/pytenet/qnumber.py:39\u001b[0m, in \u001b[0;36mis_qsparse\u001b[0;34m(A, qnums)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03mTest whether sparsity structure of `A` matches quantum numbers, i.e., if the\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03mquantum numbers corresponding to non-zero entries in `A` sum to zero.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     38\u001b[0m mask \u001b[38;5;241m=\u001b[39m qnumber_outer_sum(qnums)\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_Krylov = 50\n",
    "psi_original = copy.deepcopy(hartree_state)\n",
    "max_bond_Krylov = 40\n",
    "#max_bond_Krylov = 80\n",
    "trunc_tol = 0\n",
    "foldername = f\"water_Krylov\"\n",
    "#Krylov vectors are included in data, you dont have to run generate it. ofc, you can -regenerate it to verify the algorithm using the following code:\n",
    "\n",
    "generate_krylov_space_in_disk(N_Krylov, H_mu_nu_list_spin_layer, psi_original, max_bond_Krylov, trunc_tol, r_thc, foldername)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make use of method proposed in https://journals.aps.org/prb/abstract/10.1103/PhysRevB.85.205119 to improve the orthogonality of Krylov vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work_fast/ge49cag/pytenet_thc/pytenet/operation_thc.py:214: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  W[i,j] = np.vdot(temp1.as_vector(), temp2.as_vector())\n"
     ]
    }
   ],
   "source": [
    "W = get_W(N_Krylov, foldername)\n",
    "S = get_S(W)\n",
    "vector_list = generate_re_ortho_space(N_Krylov, W, foldername)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After achieving Krylov vectors, we implement Lanczos algorithm using these Krylov vectors. In this notebook, all the expectation values are calculated using ED for convenience. Since calculating the expectation value (contracting the tensor network) doesn't bring new errors, it makes no difference whether we use tensor network or ED to calculate the matrix elements for reduced Hamiltonian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work_fast/ge49cag/pytenet_thc/pytenet/operation_thc.py:281: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  H_reduced[i, j] = np.vdot(vector_list[i], H@vector_list[j])\n"
     ]
    }
   ],
   "source": [
    "H_reduced = generate_reduced_H(vector_list, H_correct_10e)\n",
    "N_list = [0]\n",
    "mps_start = copy.deepcopy(hartree_state)\n",
    "error_list = [np.vdot(mps_start.as_vector(), H_correct_10e@(mps_start.as_vector())) - e_ground]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35244435+0.j]\n",
      "[0.02484897+0.j]\n",
      "[0.00195854+0.j]\n",
      "[7.230799e-05+0.j]\n",
      "[8.51511174e-07+0.j]\n",
      "[1.42243124e-08+0.j]\n",
      "[1.02559738e-10+0.j]\n",
      "[-5.68434189e-14+0.j]\n",
      "[-1.42108547e-13+0.j]\n",
      "[-1.42108547e-13+0.j]\n"
     ]
    }
   ],
   "source": [
    "for N in range(5, N_Krylov+1, 5):\n",
    "    N_list.append(N)\n",
    "    H_part = H_reduced[:N, :N]\n",
    "    e_rotate, v_rotate = np.linalg.eigh(H_part)\n",
    "\n",
    "    v_rotate_ground = v_rotate[:,0][0]* vector_list[0]\n",
    "    for i in range (1, N):\n",
    "        v_rotate_ground += v_rotate[:,0][i]* vector_list[i]\n",
    "    v_rotate_ground /= norm(v_rotate_ground)\n",
    "    e_new = np.vdot(v_rotate_ground, H_correct_10e@v_rotate_ground)\n",
    "    error_list.append(e_new - e_ground)\n",
    "    \n",
    "    print(e_new - e_ground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
