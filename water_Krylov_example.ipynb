{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pytenet.hartree_fock_mps import generate_single_state\n",
    "from pytenet.hamiltonian_thc import eval_func, generate_thc_mpos_by_layer_qn, get_t_spin\n",
    "from pytenet.global_krylov_method import generate_krylov_space_in_disk, get_W, get_S, generate_re_ortho_space, generate_reduced_H, generate_Hamiltonian_with_occupation_number\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import copy\n",
    "import h5py\n",
    "from numpy.linalg import norm\n",
    "#np.set_printoptions(precision=4,suppress=True)\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and initialize datas: \n",
    "\n",
    "no is number of spatial orbitals\n",
    "\n",
    "L is number of spinor orbitals, L = 2*no\n",
    "\n",
    "t_spin is one-body integral in Chemist's notation (considering spins)\n",
    "\n",
    "g_spin is two-body integral in Chemist's notation (considering spins)\n",
    "\n",
    "X_mo and Z_mo are THC tensors, X_mo_up/down are X_mo considering spins\n",
    "\n",
    "r_THC is THC rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "(7, 28)\n",
      "(28, 28)\n",
      "rl errV: 2.8386751875274264e-12\n",
      "abs errV: 2.0615721155266396e-11\n",
      "errt: 7.097049412242525e-13\n",
      "errh: 2.585427402664151e-13\n",
      "errht: 9.079449636842276e-14\n"
     ]
    }
   ],
   "source": [
    "#load integrals\n",
    "with h5py.File(\"data_water/eri_water.hdf5\", \"r\") as f:\n",
    "#with h5py.File(\"/work_fast/ge49cag/pytenet_yu/water/eri_water.hdf5\", \"r\") as f:\n",
    "    eri = f[\"eri\"][()]\n",
    "    hkin = f[\"hkin\"][()]\n",
    "    hnuc = f[\"hnuc\"][()]\n",
    "\n",
    "#print(np.linalg.norm(eri))\n",
    "#print(eri.shape)\n",
    "\n",
    "no = eri.shape[0]\n",
    "MV = eri.reshape(no*no,no*no)\n",
    "\n",
    "u = np.load(\"data_water/x.npy\")\n",
    "#u = np.load(\"/work_fast/ge49cag/pytenet_yu/water/x.npy\")\n",
    "X_mo = u.transpose(1,0)\n",
    "g_thc, Z_mo = eval_func(u,eri,hkin,hnuc,)\n",
    "h1 = hnuc+hkin\n",
    "nmo = X_mo.shape[1]\n",
    "L = 2*X_mo.shape[1]\n",
    "g_thc = g_thc.reshape(nmo, nmo, nmo, nmo)\n",
    "r_thc = X_mo.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These Hamiltonian are exact molecular Hamiltonian and molecular Hamiltonian reconstructed by THC tensors. The calculation cost time, so that we store them in disk and load them when needed. For water molecule H2O in STO-6G basis, the error is small for r_THC = 28.\n",
    "\n",
    "Actually, considering there are always 10 electrons for a water molecule, we only retain the elements which operator quantum states with 10 electrons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ge49cag/.local/lib/python3.10/site-packages/scipy/sparse/_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "#load Hamiltonian generated by above coefficients\n",
    "H_correct = scipy.io.mmread('data_water/H_water_correct.mtx').tocsr()\n",
    "e1, v1 = sparse.linalg.eigsh(H_correct, which = 'SA', k = 1)\n",
    "e_ground = e1\n",
    "\n",
    "H_correct_10e = generate_Hamiltonian_with_occupation_number(H_correct.real, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate THC-MPO by layers, using THC tensors. \n",
    "t_spin is used to create MPO for kinetic term.\n",
    "It returns a list of H_mu_nu, each H_mu_nu is also a list, which contains four smaller MPOs with bond dims 2.\n",
    "The final element of this list is MPO for kinetic term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'pytenet.mpo.MPO'>\n",
      "[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "#generate thc_mpo\n",
    "t_spin = get_t_spin(h1, eri)\n",
    "H_mu_nu_list_spin_layer = generate_thc_mpos_by_layer_qn(X_mo, Z_mo, L, t_spin)\n",
    "\n",
    "print(type(H_mu_nu_list_spin_layer))\n",
    "print(type(H_mu_nu_list_spin_layer[0]))\n",
    "print(type(H_mu_nu_list_spin_layer[0][0]))\n",
    "print((H_mu_nu_list_spin_layer[0][0].bond_dims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ground state finding, we use Hatree fock state |11111111110000> as initial state.\n",
    "\n",
    "For 1st excited state, please use single-excited Hatree-Fock state as initial state, or even superposition of several single-excited Hatree-Fock states as initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hartree_state = generate_single_state(14, [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0])\n",
    "hartree_state_vector = hartree_state.as_vector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate a group of orthogonal Krylov vectors using THC-MPO, with bond dim 40 for Krylov vectors. The vectors are stored in the folder = 'foldername', thus you don't have to generate them again for next time use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Krylov = 50\n",
    "psi_original = copy.deepcopy(hartree_state)\n",
    "max_bond_Krylov = 40\n",
    "#max_bond_Krylov = 80\n",
    "trunc_tol = 0\n",
    "foldername = f\"water_Krylov\"\n",
    "#Krylov vectors are included in data, you dont have to run generate it. ofc, you can -regenerate it to verify the algorithm using the following code:\n",
    "\n",
    "generate_krylov_space_in_disk(N_Krylov, H_mu_nu_list_spin_layer, psi_original, max_bond_Krylov, trunc_tol, r_thc, foldername)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make use of method proposed in https://journals.aps.org/prb/abstract/10.1103/PhysRevB.85.205119 to improve the orthogonality of Krylov vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work_fast/ge49cag/pytenet_thc/pytenet/operation_thc.py:214: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  W[i,j] = np.vdot(temp1.as_vector(), temp2.as_vector())\n"
     ]
    }
   ],
   "source": [
    "W = get_W(N_Krylov, foldername)\n",
    "S = get_S(W)\n",
    "vector_list = generate_re_ortho_space(N_Krylov, W, foldername)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After achieving Krylov vectors, we implement Lanczos algorithm using these Krylov vectors. In this notebook, all the expectation values are calculated using ED for convenience. Since calculating the expectation value (contracting the tensor network) doesn't bring new errors, it makes no difference whether we use tensor network or ED to calculate the matrix elements for reduced Hamiltonian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work_fast/ge49cag/pytenet_thc/pytenet/operation_thc.py:281: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  H_reduced[i, j] = np.vdot(vector_list[i], H@vector_list[j])\n"
     ]
    }
   ],
   "source": [
    "H_reduced = generate_reduced_H(vector_list, H_correct_10e)\n",
    "N_list = [0]\n",
    "mps_start = copy.deepcopy(hartree_state)\n",
    "error_list = [np.vdot(mps_start.as_vector(), H_correct_10e@(mps_start.as_vector())) - e_ground]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35244435+0.j]\n",
      "[0.02484897+0.j]\n",
      "[0.00195854+0.j]\n",
      "[7.230799e-05+0.j]\n",
      "[8.51511174e-07+0.j]\n",
      "[1.42243124e-08+0.j]\n",
      "[1.02559738e-10+0.j]\n",
      "[-5.68434189e-14+0.j]\n",
      "[-1.42108547e-13+0.j]\n",
      "[-1.42108547e-13+0.j]\n"
     ]
    }
   ],
   "source": [
    "for N in range(5, N_Krylov+1, 5):\n",
    "    N_list.append(N)\n",
    "    H_part = H_reduced[:N, :N]\n",
    "    e_rotate, v_rotate = np.linalg.eigh(H_part)\n",
    "\n",
    "    v_rotate_ground = v_rotate[:,0][0]* vector_list[0]\n",
    "    for i in range (1, N):\n",
    "        v_rotate_ground += v_rotate[:,0][i]* vector_list[i]\n",
    "    v_rotate_ground /= norm(v_rotate_ground)\n",
    "    e_new = np.vdot(v_rotate_ground, H_correct_10e@v_rotate_ground)\n",
    "    error_list.append(e_new - e_ground)\n",
    "    \n",
    "    print(e_new - e_ground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
